<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0" uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>An easier way to generate PDFs from HTML templates</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/03/11/easier-way-generate-pdfs-html-templates" /><author><name>Muhammad Edwin</name></author><id>7d5e3e90-0a15-4812-9a92-fc9fcd2e2228</id><updated>2022-03-11T07:00:00Z</updated><published>2022-03-11T07:00:00Z</published><summary type="html">&lt;p&gt;Applications frequently are required to generate invoices, reports, ID cards, and much more in PDF format. There are &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt; libraries and tools that developers can use to generate PDFs, including the popular &lt;a href="https://community.jaspersoft.com/project/jasperreports-library"&gt;JasperReports&lt;/a&gt;. While sophisticated, using these programs can be complicated because they support a wide range of documents.&lt;/p&gt; &lt;p&gt;This article introduces a simpler tool, the open source &lt;a href="https://wkhtmltopdf.org"&gt;wkhtmltopdf&lt;/a&gt; utility. I will show you how to use &lt;code&gt;wkhtmltopdf&lt;/code&gt; to solve a common scenario: You have an HTML form, parameterized to accept input data, and you need to produce a PDF from the data in that form. You will learn how to set up your data and make a call to the &lt;code&gt;wkhtmltopdf&lt;/code&gt; utility from a &lt;a href="https://developers.redhat.com/topics/spring-boot"&gt;Spring Boot&lt;/a&gt; web application. We'll use Red Hat's &lt;a href="https://developers.redhat.com/products/rhel/ubi"&gt;Universal Base Image&lt;/a&gt; (UBI) 8 as a base image to simplify the application build, then deploy the final image into &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat Openshift&lt;/a&gt; 4.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note:&lt;/strong&gt; You can find the code for the example in my &lt;a href="https://github.com/edwin/spring-boot-and-wkhtmltopdf"&gt;GitHub repository&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Configuration using Maven&lt;/h2&gt; &lt;p&gt;Let's start with a Maven file. I'm using a &lt;a href="https://snowdrop.dev"&gt;Snowdrop&lt;/a&gt; &lt;a href="https://www.baeldung.com/spring-maven-bom"&gt;bill of materials&lt;/a&gt; (BOM) on my Maven project object model (POM) file instead of a community version of Spring Boot:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-xml"&gt;&lt;?xml version="1.0" encoding="UTF-8"?&gt; &lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.edw&lt;/groupId&gt; &lt;artifactId&gt;SpringBootAndPdf&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;redhat-early-access&lt;/id&gt; &lt;name&gt;Red Hat Early Access Repository&lt;/name&gt; &lt;url&gt;https://maven.repository.redhat.com/earlyaccess/all/&lt;/url&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;redhat-ga&lt;/id&gt; &lt;name&gt;Red Hat GA Repository&lt;/name&gt; &lt;url&gt;https://maven.repository.redhat.com/ga/&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;redhat-early-access&lt;/id&gt; &lt;name&gt;Red Hat Early Access Repository&lt;/name&gt; &lt;url&gt;https://maven.repository.redhat.com/earlyaccess/all/&lt;/url&gt; &lt;/pluginRepository&gt; &lt;pluginRepository&gt; &lt;id&gt;redhat-ga&lt;/id&gt; &lt;name&gt;Red Hat GA Repository&lt;/name&gt; &lt;url&gt;https://maven.repository.redhat.com/ga/&lt;/url&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;properties&gt; &lt;snowdrop-bom.version&gt;2.4.9.Final-redhat-00001&lt;/snowdrop-bom.version&gt; &lt;spring-boot.version&gt;2.1.4.RELEASE-redhat-00001&lt;/spring-boot.version&gt; &lt;maven.compiler.source&gt;11&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;11&lt;/maven.compiler.target&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;dev.snowdrop&lt;/groupId&gt; &lt;artifactId&gt;snowdrop-dependencies&lt;/artifactId&gt; &lt;version&gt;${snowdrop-bom.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;app&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;version&gt;${spring-boot.version}&lt;/version&gt; &lt;configuration&gt; &lt;mainClass&gt;com.edw.Main&lt;/mainClass&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt;&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;The Spring Boot program&lt;/h2&gt; &lt;p&gt;Our main class in Java is:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;package com.edw; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class Main { public static void main(String[] args) { SpringApplication.run(Main.class, args); } }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The following &lt;code&gt;Controller&lt;/code&gt; class displays a generated PDF. One of the class's most important tasks is to display the PDF properly in a browser; this task is achieved by setting up a proper &lt;code&gt;MediaType&lt;/code&gt; that produces an &lt;code&gt;application/pdf&lt;/code&gt; content-type header. Another important task is to call an external process that runs &lt;code&gt;wkhtmltopdf&lt;/code&gt; to trigger the conversion from HTML to PDF:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;package com.edw.controllers; import org.springframework.http.MediaType; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestParam; import org.springframework.web.bind.annotation.ResponseBody; import java.nio.file.Files; import java.nio.file.Path; import java.nio.file.Paths; import java.util.Scanner; import java.util.UUID; @Controller public class ReportController { @GetMapping( value = "/generate-report", produces = MediaType.APPLICATION_PDF_VALUE ) public @ResponseBody byte[] generateReport(@RequestParam(value = "name") String name, @RequestParam(value = "address") String address) throws Exception { String uuid = UUID.randomUUID().toString(); Path pathHtml = Paths.get("/tmp/" + uuid + ".html"); Path pathPdf = Paths.get("/tmp/" + uuid + ".pdf"); try { // read the template and fill the data String htmlContent = new Scanner(getClass().getClassLoader().getResourceAsStream("template.html"), "UTF-8") .useDelimiter("\\A") .next(); htmlContent = htmlContent.replace("$name", name) .replace("$address", address); // write to html Files.write(pathHtml, htmlContent.getBytes()); // convert html to pdf Process generateToPdf = Runtime.getRuntime().exec("wkhtmltopdf " + pathHtml.toString() + " " + pathPdf.toString() ); generateToPdf.waitFor(); // deliver pdf return Files.readAllBytes(pathPdf); } finally { // delete temp files Files.delete(pathHtml); Files.delete(pathPdf); } } }&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Formatting the HTML data&lt;/h2&gt; &lt;p&gt;The following HTML template generates a report with input data consisting of names (the &lt;code&gt;$name&lt;/code&gt; parameter) and addresses (the &lt;code&gt;$address&lt;/code&gt; parameter):&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;&lt;html&gt; &lt;head&gt; &lt;style&gt; &lt;!-- put your css here --&gt; &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;div class="container" style="padding-top: 100px;"&gt; &lt;div class="row justify-content-center"&gt; &lt;div class="col-md-6"&gt; &lt;table class="table table-bordered"&gt; &lt;thead class="thead-light"&gt; &lt;tr&gt; &lt;th&gt;Name&lt;/th&gt; &lt;th&gt;Address&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;$name&lt;/td&gt; &lt;td&gt;$address&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt;&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Installing the wkhtmltopdf program&lt;/h2&gt; &lt;p&gt;This next part is where the magic happens. First, you need to download &lt;code&gt;wkhtmltopdf&lt;/code&gt; from GitHub and extract the program. After that, you can create a &lt;code&gt;wkhtml&lt;/code&gt; folder within your Java project and copy &lt;code&gt;wkhtmltopdf&lt;/code&gt; to the application's folder from the &lt;code&gt;bin&lt;/code&gt; folder:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ wget https://github.com/wkhtmltopdf/wkhtmltopdf/releases/download/0.12.4/wkhtmltox-0.12.4_linux-generic-amd64.tar.xz $ tar -xf wkhtmltox-0.12.4_linux-generic-amd64.tar.xz $ mkdir /code/wkhtml $ cp wkhtmltox/bin/wkhtmltopdf /code/wkhtml/&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The resulting directory structure looks like:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;+--- .gitignore +--- Dockerfile +--- pom.xml +--- src | +--- main | | +--- java | | | +--- com | | | | +--- edw | | | | | +--- controllers | | | | | | +--- HelloWorldController.java | | | | | | +--- ReportController.java | | | | | +--- Main.java | | +--- resources | | | +--- application.properties | | | +--- template.html | +--- test | | +--- java +--- wkhtml | +--- wkhtmltopdf&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Building the image&lt;/h2&gt; &lt;p&gt;The following Dockerfile uses UBI 8 as the base image:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;FROM registry.access.redhat.com/ubi8/openjdk-11-runtime:1.10 USER root ENV LANG='en_US.UTF-8' LANGUAGE='en_US:en' TZ='Asia/Jakarta' RUN microdnf update &amp;&amp; \ microdnf install tzdata libXrender libXext fontconfig &amp;&amp; \ ln -sf /usr/share/zoneinfo/$TZ /etc/localtime &amp;&amp; \ microdnf clean all COPY wkhtml/wkhtmltopdf /usr/local/bin/ EXPOSE 8080 USER 185 COPY target/app.jar /deployments/app.jar ENTRYPOINT [ "java", "-jar", "/deployments/app.jar" ]&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now, build your image and run it:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ docker build -t springboot-and-pdf . $ docker run -p 8080:8080 springboot-and-pdf&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In your browser, enter the &lt;code&gt;generate-report&lt;/code&gt; URL with a name and address as parameters, and you get a PDF ready to download and print, as shown in Figure 1.&lt;/p&gt; &lt;figure role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/report-pdf.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/report-pdf.png?itok=1D-Td2jX" width="600" height="269" alt="The application displays a PDF reflecting the application's HTML template." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1. The Spring Boot application generates a PDF report from the data in an HTML template. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;The streamlined process shown in this example is useful in a variety of situations where you want to generate a report with tabular data or another structured PDF based on input data. Feel free to leave comments on this article to discuss where you might use this approach and any questions you may have.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/03/11/easier-way-generate-pdfs-html-templates" title="An easier way to generate PDFs from HTML templates"&gt;An easier way to generate PDFs from HTML templates&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Muhammad Edwin</dc:creator><dc:date>2022-03-11T07:00:00Z</dc:date></entry><entry><title type="html">This Week in JBoss - 11 March 2022</title><link rel="alternate" href="https://www.jboss.org/posts/weekly-2022-03-11.html" /><category term="quarkus" /><category term="kogito" /><category term="java" /><category term="camel" /><category term="hibernate" /><category term="narayana" /><category term="wildfly" /><category term="cdi-test" /><author><name>Alex Porcelli</name><uri>https://www.jboss.org/people/alex-porcelli</uri><email>do-not-reply@jboss.com</email></author><id>https://www.jboss.org/posts/weekly-2022-03-11.html</id><updated>2022-03-11T00:00:00Z</updated><content type="html">&lt;article class="" data-tags="quarkus, kogito, java, camel, hibernate, narayana, wildfly, cdi-test"&gt; &lt;h1&gt;This Week in JBoss - 11 March 2022&lt;/h1&gt; &lt;p class="preamble"&gt;&lt;/p&gt;&lt;p&gt;Happy Friday, everyone!&lt;/p&gt; &lt;p&gt;Welcome to another edition of the JBoss Editorial that brings you news and updates from your favorite communities.&lt;/p&gt;&lt;p&gt;&lt;/p&gt; &lt;div class="sect1"&gt; &lt;h2 id="_release_roundup"&gt;Release roundup&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Here are the most recent releases for this edition:&lt;/p&gt; &lt;div class="ulist square"&gt; &lt;ul class="square"&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://quarkus.io/blog/quarkus-2-7-4-final-released/"&gt;Quarkus 2.7.4&lt;/a&gt; maintenance release with a new round of bugfixes and documentation improvements. This should be a safe upgrade upgrade for anyone already using 2.7.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://quarkus.io/blog/intellij-quarkus-tools-1.10.0/"&gt;Quarkus Tools for IntelliJ 1.10.0&lt;/a&gt; release that adds support for Quarkus run/debug configurations and provides several fixes (including security related!).&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://blog.kie.org/2022/03/kogito-1-18-0-released.html"&gt;Kogito 1.18.0&lt;/a&gt; release includes a number of new bug fixes and new features, especially for Serverless Workflows.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://camel.apache.org/blog/2022/03/RELEASE-3.14.2/"&gt;Camel 3.14.2 LTS&lt;/a&gt; new patch release with 27 improvements and fixes.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://in.relation.to/2022/03/09/orm-600-cr2/"&gt;Hibernate ORM 6.0.0.CR2&lt;/a&gt; is expected to be the last release candidate before the 6.0 final release.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://in.relation.to/2022/03/02/hibernate-validator-703-622-final-released/"&gt;Hibernate Validator 6.2.2.Final, 7.0.3.Final and 8.0.0.Alpha1&lt;/a&gt;. Maintenance releases for Hibernate Validator 6.2 and 7.0 branches - both versions bring back support for validating java.sql.Date. The 8.0.0.Alpha1 targets specifically the upcoming Jakarta EE 10.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_testing_jakarta_ee_applications_with_cdi_test"&gt;Testing Jakarta EE applications with CDI-test&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="http://www.mastertheboss.com/java-ee/jakarta-ee/testing-jakarta-ee-applications-with-cdi-test/"&gt;Testing Jakarta EE applications with CDI-test&lt;/a&gt;, by Gunnar Hilling&lt;/p&gt; &lt;p&gt;In this post, Gunnar presents the CDI-Test JUnit 5 extension, which provides a clever mechanism for unit, component, and integration Jakarta EE application tests at scale.&lt;/p&gt; &lt;p&gt;Gunnar provides a sample repository with a fully functional application and its test so you can use it to follow along with the article.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_narayana_community_priorities"&gt;Narayana Community Priorities&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="https://jbossts.blogspot.com/2022/03/narayana-community-priorities.html"&gt;Narayana Community Priorities&lt;/a&gt;&lt;/p&gt; &lt;p&gt;This excellent post from Narayana outlines the project’s near-term priorities based on the community’s feedback.&lt;/p&gt; &lt;p&gt;The topics covered by the post include Community Engagement, Java Versions, Integrating with contemporary services, Cloud strategy, and more.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_camel_k_roadmap"&gt;Camel K Roadmap&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="https://camel.apache.org/blog/2022/03/camel-k-roadmap-2022/"&gt;Camel K Roadmap&lt;/a&gt;, by Pasquale Congiusti&lt;/p&gt; &lt;p&gt;One more great example of what’s planned for the project published in the open! This time Pasquale provides a comprehensive roadmap for the Camel K project for 2022.&lt;/p&gt; &lt;p&gt;Although these plans aren’t commitments, they provide an excellent understanding of where the project is heading.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_wildfly_on_the_cloud_with_helm"&gt;WildFly on the Cloud with Helm&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="http://www.mastertheboss.com/soa-cloud/openshift/wildfly-on-the-cloud-with-helm/"&gt;WildFly on the Cloud with Helm&lt;/a&gt;, by Francesco Marchioni&lt;/p&gt; &lt;p&gt;The popularity of Helm charts among developers is great. In this article, Francesco provides a step-by-step guide on how to deploy a WildFly application on OpenShift using bootable-jar and source to image.&lt;/p&gt; &lt;p&gt;New to Helm Charts? No worries, Francesco also covers a basic Helm setup.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_editing_serverless_workflow_definitions_with_vscode"&gt;Editing Serverless Workflow Definitions with VSCode&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="https://blog.kie.org/2022/03/editing-serverless-workflow-definitions-with-our-new-vscode-extension.html"&gt;Editing Serverless Workflow Definitions with our new VSCode Extension&lt;/a&gt;, by Paulo Martins&lt;/p&gt; &lt;p&gt;Here we have Paulo introducing the new VSCode extension for Serverless Workflow provided by Red Hat, which allows users to have a side-by-side real-time preview of their workflows while editing JSON and YAML files inside VSCode.&lt;/p&gt; &lt;p&gt;Serverless Workflow is a CNCF based specification for workflows that Kogito already supports; check this out!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_content_based_routing_with_quarkus_and_kogito"&gt;Content based routing with Quarkus and Kogito&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="https://blog.kie.org/2022/03/content-based-routing-with-quarkus-and-kogito.html"&gt;Content based routing with Quarkus and Kogito&lt;/a&gt;, by Matteo Mortari&lt;/p&gt; &lt;p&gt;One more post about the Kogito technology! This time we have Matteo presenting a content-based router using DMN, Quarkus, Kogito, Camel, Atlas Map, Managed Kafka, and OpenShift Sandbox! Ohh my!&lt;/p&gt; &lt;p&gt;The post is very detailed, covering content with code examples and, more interesting, a link for a youtube video where Matteo explains the concepts and shows a live demo!&lt;/p&gt; &lt;p&gt;&lt;em&gt;That’s all for today! Please join us again in two weeks for another round of our JBoss editorial!&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="author"&gt; &lt;pfe-avatar pfe-shape="circle" pfe-pattern="squares" pfe-src="/img/people/alex-porcelli.png"&gt;&lt;/pfe-avatar&gt; &lt;span&gt;Alex Porcelli&lt;/span&gt; &lt;/div&gt;&lt;/article&gt;</content><dc:creator>Alex Porcelli</dc:creator></entry><entry><title type="html">Testing Jakarta EE applications with CDI-test</title><link rel="alternate" href="http://www.mastertheboss.com/java-ee/jakarta-ee/testing-jakarta-ee-applications-with-cdi-test/" /><author><name>Gunnar Hilling</name></author><id>http://www.mastertheboss.com/java-ee/jakarta-ee/testing-jakarta-ee-applications-with-cdi-test/</id><updated>2022-03-10T09:25:02Z</updated><content type="html">This article introduces the Testing framework CDI-Test which you can use to test JakartaEE and Microprofile applications at scale. CDI Test: why you need it First of all: We all love developing in the Java EE ecosystem. Or at least we do since version 5… Or maybe we don’t but our employers do. Partly because ... The post appeared first on .</content><dc:creator>Gunnar Hilling</dc:creator></entry><entry><title>Modular Perl in Red Hat Enterprise Linux 8</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/03/10/modular-perl-red-hat-enterprise-linux-8" /><author><name>Petr Pisar</name></author><id>67e169d8-c02b-42b1-9ca0-803a73930efa</id><updated>2022-03-10T07:00:00Z</updated><published>2022-03-10T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/products/rhel"&gt;Red Hat Enterprise Linux&lt;/a&gt; in &lt;a href="https://www.redhat.com/en/enterprise-linux-8"&gt;version 8&lt;/a&gt; (RHEL 8) comes with &lt;em&gt;modules&lt;/em&gt;, a packaging concept that allows system administrators to select the desired software version from multiple packaged versions. This article shows you how to manage Perl as a module, as well as how to manage the CPAN modules provided by Perl, in RHEL 8.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: The term &lt;em&gt;module&lt;/em&gt; in this article is used for both RHEL modules and Perl modules. I will refer to the "modularity module" for the Red Hat Enterprise Linux type and the "CPAN module" for the Perl type.&lt;/p&gt; &lt;h2&gt;Installing Perl from the default stream&lt;/h2&gt; &lt;p&gt;Start by installing Perl in a simple manner:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;# yum --allowerasing install perl Last metadata expiration check: 1:37:36 ago on Tue 07 May 2019 04:18:01 PM CEST. Dependencies resolved. ========================================================================================== Package Arch Version Repository Size ========================================================================================== Installing: perl x86_64 4:5.26.3-416.el8 rhel-8.0.z-appstream 72 k Installing dependencies: […] Transaction Summary ========================================================================================== Install 147 Packages Total download size: 21 M Installed size: 59 M Is this ok [y/N]: y […] perl-threads-shared-1.58-2.el8.x86_64 Complete!&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Next, check which version of Perl you have:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ perl -V:version version='5.26.3';&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The output shows that you have Perl 5.26.3. This is the default version supported for the next 10 years. If you are fine with that, then you don't need to worry about modules. But what if you want to try a different version? There are various reasons for enabling another version of your software. Most often, you might have an existing application that depends on a combination of modules, and some don't work with updated versions of Perl. Not all modules are compatible with other modules.&lt;/p&gt; &lt;p&gt;For the remainder of this article, we will look at how to install Perl modules using streams.&lt;/p&gt; &lt;h2&gt;Exploring streams in RHEL 8&lt;/h2&gt; &lt;p&gt;Find out what Perl modules are available using the &lt;code&gt;yum module list&lt;/code&gt; command:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;# yum module list Last metadata expiration check: 1:45:10 ago on Tue 07 May 2019 04:18:01 PM CEST. […] Name Stream Profiles Summary […] parfait 0.5 common Parfait Module perl 5.24 common [d], Practical Extraction and Report Languag minimal e perl 5.26 [d] common [d], Practical Extraction and Report Languag minimal e perl-App-cpanminus 1.7044 [d] common [d] Get, unpack, build and install CPAN mod ules perl-DBD-MySQL 4.046 [d] common [d] A MySQL interface for Perl perl-DBD-Pg 3.7 [d] common [d] A PostgreSQL interface for Perl perl-DBD-SQLite 1.58 [d] common [d] SQLite DBI driver perl-DBI 1.641 [d] common [d] A database access API for Perl perl-FCGI 0.78 [d] common [d] FastCGI Perl bindings perl-YAML 1.24 [d] common [d] Perl parser for YAML php 7.2 [d] common [d], PHP scripting language devel, minim al […] &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The output shows that a module is available for both Perl 5.24 and Perl 5.26. These are called &lt;em&gt;streams&lt;/em&gt; in the modularity world, and they denote independent variants of the same software stack, usually different versions. The &lt;code&gt;[d]&lt;/code&gt; flag marks a default stream, which is the one installed if you do not explicitly enable a different stream. So the previous output explains why &lt;code&gt;yum&lt;/code&gt; installed Perl 5.26.3 and not one of the 5.24 micro versions.&lt;/p&gt; &lt;p&gt;In general, any module can have multiple streams. At most, one stream can be the default, and another stream can be enabled. An enabled stream takes precedence over a default one. If there is no enabled or a default stream, the content of the module is unavailable.&lt;/p&gt; &lt;p&gt;Now, let's make a few assumptions:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;You have an old application that you are migrating from RHEL 7.&lt;/li&gt; &lt;li&gt;The application depends on the &lt;code&gt;rh-perl524&lt;/code&gt; &lt;a href="https://www.redhat.com/en/resources/red-hat-software-collections"&gt;Red Hat Software Collections&lt;/a&gt; environment.&lt;/li&gt; &lt;li&gt;You want to give it a try on RHEL 8.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Based on these assumptions, you will want to install Perl 5.24 on RHEL 8.&lt;/p&gt; &lt;h2&gt;Enabling a stream&lt;/h2&gt; &lt;p&gt;First, switch the Perl module to the 5.24 stream:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;# yum module enable perl:5.24 Last metadata expiration check: 2:03:16 ago on Tue 07 May 2019 04:18:01 PM CEST. Problems in request: Modular dependency problems with Defaults: Problem 1: conflicting requests - module freeradius:3.0:8000020190425181943:75ec4169-0.x86_64 requires module(perl:5.26), but none of the providers can be installed - module perl:5.26:820181219174508:9edba152-0.x86_64 conflicts with module(perl:5.24) provided by perl:5.24:820190207164249:ee766497-0.x86_64 - module perl:5.24:820190207164249:ee766497-0.x86_64 conflicts with module(perl:5.26) provided by perl:5.26:820181219174508:9edba152-0.x86_64 Problem 2: conflicting requests - module freeradius:3.0:820190131191847:fbe42456-0.x86_64 requires module(perl:5.26), but none of the providers can be installed - module perl:5.26:820181219174508:9edba152-0.x86_64 conflicts with module(perl:5.24) provided by perl:5.24:820190207164249:ee766497-0.x86_64 - module perl:5.24:820190207164249:ee766497-0.x86_64 conflicts with module(perl:5.26) provided by perl:5.26:820181219174508:9edba152-0.x86_64 Dependencies resolved. ========================================================================================== Package Arch Version Repository Size ========================================================================================== Enabling module streams: perl 5.24 Transaction Summary ========================================================================================== Is this ok [y/N]: y Complete! Switching module streams does not alter installed packages (see 'module enable' in dnf(8) for details)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;We get a warning that the &lt;code&gt;freeradius:3.0&lt;/code&gt; stream is not compatible with &lt;code&gt;perl:5.24&lt;/code&gt;. That's because FreeRADIUS was built for Perl 5.26 only. Let's assume that your application fortunately doesn't require FreeRADIUS.&lt;/p&gt; &lt;p&gt;Next, the command displays a confirmation that it is enabling the Perl 5.24 stream. And, finally, there is another warning about installed packages. The last warning means that the system might still contain RPM packages from the Perl 5.26 stream, and you need to explicitly sort them out.&lt;/p&gt; &lt;p&gt;If you happen to receive the following error message instead, you have already enabled the &lt;code&gt;perl:5.26&lt;/code&gt; stream and &lt;code&gt;yum&lt;/code&gt; does not allow you to switch a module away from an already enabled stream for safety reasons:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;The operation would result in switching of module 'perl' stream '5.26' to stream '5.24' Error: It is not possible to switch enabled streams of a module unless explicitly enabled via configuration option module_stream_switch. It is recommended to rather remove all installed content from the module, and reset the module using 'yum module reset &lt;module_name&gt;' command. After you reset the module, you can install the other stream.&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To recover from the safety block, follow the recommendation in the message and reset the &lt;code&gt;perl&lt;/code&gt; module with the &lt;code&gt;yum module reset perl&lt;/code&gt; command. Then you will be able to enable the &lt;code&gt;perl:5.24&lt;/code&gt; stream.&lt;/p&gt; &lt;p&gt;Changing modules and changing packages are two separate phases. You can fix it by synchronizing the distribution content like this:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;# yum --allowerasing distrosync Last metadata expiration check: 0:00:56 ago on Tue 07 May 2019 06:33:36 PM CEST. Modular dependency problems: Problem 1: module freeradius:3.0:8000020190425181943:75ec4169-0.x86_64 requires module(perl:5.26), but none of the providers can be installed - module perl:5.26:820181219174508:9edba152-0.x86_64 conflicts with module(perl:5.24) provided by perl:5.24:820190207164249:ee766497-0.x86_64 - module perl:5.24:820190207164249:ee766497-0.x86_64 conflicts with module(perl:5.26) provided by perl:5.26:820181219174508:9edba152-0.x86_64 - conflicting requests Problem 2: module freeradius:3.0:820190131191847:fbe42456-0.x86_64 requires module(perl:5.26), but none of the providers can be installed - module perl:5.26:820181219174508:9edba152-0.x86_64 conflicts with module(perl:5.24) provided by perl:5.24:820190207164249:ee766497-0.x86_64 - module perl:5.24:820190207164249:ee766497-0.x86_64 conflicts with module(perl:5.26) provided by perl:5.26:820181219174508:9edba152-0.x86_64 - conflicting requests Dependencies resolved. ========================================================================================== Package Arch Version Repository Size ========================================================================================== […] Downgrading: perl x86_64 4:5.24.4-403.module+el8+2770+c759b41a rhel-8.0.z-appstream 6.1 M […] Transaction Summary ========================================================================================== Upgrade 69 Packages Downgrade 66 Packages Total download size: 20 M Is this ok [y/N]: y […] Complete!&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Check your version with the &lt;code&gt;perl&lt;/code&gt; command again:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ perl -V:version version='5.24.4';&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Great! Installing the non-default module worked. The desired version of Perl is installed to a standard path (&lt;code&gt;/usr/bin/perl&lt;/code&gt;) and is therefore invoked with the &lt;code&gt;perl&lt;/code&gt; command. No &lt;code&gt;scl enable&lt;/code&gt; incantation is needed, in contrast to a requirement associated with the old software collections.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note:&lt;/strong&gt; A future &lt;code&gt;yum&lt;/code&gt; update will clean up the unnecessary warning about FreeRADIUS. I'll show some Perl-ish modules that are compatible with any Perl stream later in this article.&lt;/p&gt; &lt;h2&gt;Dependent modules&lt;/h2&gt; &lt;p&gt;Let's suppose that the old application mentioned earlier uses the &lt;code&gt;DBD::SQLite&lt;/code&gt; Perl CPAN module. So, let's install it. Yum can search for a CPAN module within a modularity module, so give the following a try:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;# yum --allowerasing install 'perl(DBD::SQLite)' […] Dependencies resolved. ========================================================================================== Package Arch Version Repository Size ========================================================================================== Installing: perl-DBD-SQLite x86_64 1.58-1.module+el8+2519+e351b2a7 rhel-8.0.z-appstream 186 k Installing dependencies: perl-DBI x86_64 1.641-2.module+el8+2701+78cee6b5 rhel-8.0.z-appstream 739 k Enabling module streams: perl-DBD-SQLite 1.58 perl-DBI 1.641 Transaction Summary ========================================================================================== Install 2 Packages Total download size: 924 k Installed size: 2.3 M Is this ok [y/N]: y […] Installed: perl-DBD-SQLite-1.58-1.module+el8+2519+e351b2a7.x86_64 perl-DBI-1.641-2.module+el8+2701+78cee6b5.x86_64 Complete!&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;DBD::SQLite&lt;/code&gt; CPAN module was found in the &lt;code&gt;perl-DBD-SQLite&lt;/code&gt; RPM package that's part of &lt;code&gt;perl-DBD-SQLite:1.58&lt;/code&gt; modularity module. It apparently requires some dependencies from the &lt;code&gt;perl-DBI:1.641&lt;/code&gt; modularity module too. After asking for confirmation, &lt;code&gt;yum&lt;/code&gt; enabled the necessary streams and installed the packages.&lt;/p&gt; &lt;p&gt;Before playing with &lt;code&gt;DBD::SQLite&lt;/code&gt; under Perl 5.24, take a look at the listing of the modularity modules and compare it with what we got the first time:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;# yum module list […] parfait 0.5 common Parfait Module perl 5.24 [e] common [d], Practical Extraction and Report Languag minimal e perl 5.26 [d] common [d], Practical Extraction and Report Languag minimal e perl-App-cpanminus 1.7044 [d] common [d] Get, unpack, build and install CPAN mod ules perl-DBD-MySQL 4.046 [d] common [d] A MySQL interface for Perl perl-DBD-Pg 3.7 [d] common [d] A PostgreSQL interface for Perl perl-DBD-SQLite 1.58 [d][e] common [d] SQLite DBI driver perl-DBI 1.641 [d][e] common [d] A database access API for Perl perl-FCGI 0.78 [d] common [d] FastCGI Perl bindings perl-YAML 1.24 [d] common [d] Perl parser for YAML php 7.2 [d] common [d], PHP scripting language devel, minim al […] &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Notice that &lt;code&gt;perl:5.24&lt;/code&gt; is enabled (&lt;code&gt;[e]&lt;/code&gt;) and thus takes precedence over &lt;code&gt;perl:5.26&lt;/code&gt;, which would otherwise be a default stream (&lt;code&gt;[d]&lt;/code&gt;). Other enabled modularity modules are &lt;code&gt;perl-DBD-SQLite:1.58&lt;/code&gt; and &lt;code&gt;perl-DBI:1.641&lt;/code&gt;. Those were enabled when you installed &lt;code&gt;DBD::SQLite&lt;/code&gt;. These two modules have no other streams.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note:&lt;/strong&gt; If you need for some reason to disable a stream, even a default one, use the &lt;code&gt;yum module disable &lt;module&gt;:&lt;stream&gt;&lt;/code&gt; command.&lt;/p&gt; &lt;p&gt;Back to some productive work. You are ready to test the &lt;code&gt;DBD::SQLite&lt;/code&gt; CPAN module. Let's create a &lt;code&gt;test&lt;/code&gt; database containing a &lt;code&gt;foo&lt;/code&gt; table with one textual column called &lt;code&gt;bar&lt;/code&gt;, and store a row containing the string &lt;code&gt;Hello&lt;/code&gt; there:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ perl -MDBI -e '$dbh=DBI-&gt;connect(q{dbi:SQLite:dbname=test}); $dbh-&gt;do(q{CREATE TABLE foo (bar text)}); $sth=$dbh-&gt;prepare(q{INSERT INTO foo(bar) VALUES(?)}); $sth-&gt;execute(q{Hello})'&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Next, verify that the &lt;code&gt;Hello&lt;/code&gt; string was indeed stored by querying the database:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ perl -MDBI -e '$dbh=DBI-&gt;connect(q{dbi:SQLite:dbname=test}); print $dbh-&gt;selectrow_array(q{SELECT bar FROM foo}), qq{\n}' Hello&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The output shows that &lt;code&gt;DBD::SQLite&lt;/code&gt; works.&lt;/p&gt; &lt;h2&gt;Installing non-modular packages with non-default streams&lt;/h2&gt; &lt;p&gt;So far, everything we want is working. But now let's see what happens if you try to install incompatible RPM packages:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;# yum --allowerasing install 'perl(LWP)' […] Error: Problem: package perl-libwww-perl-6.34-1.el8.noarch requires perl(:MODULE_COMPAT_5.26.2), but none of the providers can be installed - cannot install the best candidate for the job - package perl-libs-4:5.26.3-416.el8.i686 is excluded - package perl-libs-4:5.26.3-416.el8.x86_64 is excluded (try to add '--skip-broken' to skip uninstallable packages or '--nobest' to use not only best candidate packages)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Yum reports an error about &lt;code&gt;perl-libwww-perl&lt;/code&gt; RPM package being incompatible. The &lt;code&gt;LWP&lt;/code&gt; CPAN module that is packaged as &lt;code&gt;perl-libwww-perl&lt;/code&gt; is built only for Perl 5.26, so RPM dependencies cannot be satisfied.&lt;/p&gt; &lt;p&gt;When a &lt;code&gt;perl:5.24&lt;/code&gt; stream is enabled, the packages from the &lt;code&gt;perl:5.26&lt;/code&gt; stream are masked, meaning that they become unavailable. However, this masking does not apply to non-modular packages, such as &lt;code&gt;perl-libwww-perl&lt;/code&gt;. Many packages have not been modularized yet. If you need some of them to be available and compatible with a non-default stream (i.e., not only with Perl 5.26) do not hesitate to contact the &lt;a href="https://access.redhat.com/support"&gt;Red Hat support team&lt;/a&gt; with your request. However, make sure that your desired non-default stream &lt;a href="https://access.redhat.com/support/policy/updates/rhel8-app-streams-life-cycle"&gt;is still supported&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Resetting a module&lt;/h2&gt; &lt;p&gt;Let's say you want to find out whether your existing application works with the new Perl 5.26 version. To do that, you need to switch back to the &lt;code&gt;perl:5.26&lt;/code&gt; stream.&lt;/p&gt; &lt;p&gt;Unfortunately, it's not a straightforward process to switch from an enabled stream back to a default stream or to yet another non-default stream. You'll need to perform a module reset:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;# yum module reset perl […] Dependencies resolved. ========================================================================================== Package Arch Version Repository Size ========================================================================================== Resetting module streams: perl 5.24 Transaction Summary ========================================================================================== Is this ok [y/N]: y Complete!&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;That didn't hurt too much. Now you can synchronize the distribution again to replace the 5.24 RPM packages with 5.26 ones:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;# yum --allowerasing distrosync […] Transaction Summary ========================================================================================== Upgrade 65 Packages Downgrade 71 Packages Total download size: 22 M Is this ok [y/N]: y […]&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;After that, you can check the Perl version:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ perl -V:version version='5.26.3';&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;And check the enabled modules:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;# yum module list […] parfait 0.5 common Parfait Module perl 5.24 common [d], Practical Extraction and Report Languag minimal e perl 5.26 [d] common [d], Practical Extraction and Report Languag minimal e perl-App-cpanminus 1.7044 [d] common [d] Get, unpack, build and install CPAN mod ules perl-DBD-MySQL 4.046 [d] common [d] A MySQL interface for Perl perl-DBD-Pg 3.7 [d] common [d] A PostgreSQL interface for Perl perl-DBD-SQLite 1.58 [d][e] common [d] SQLite DBI driver perl-DBI 1.641 [d][e] common [d] A database access API for Perl perl-FCGI 0.78 [d] common [d] FastCGI Perl bindings perl-YAML 1.24 [d] common [d] Perl parser for YAML php 7.2 [d] common [d], PHP scripting language devel, minim al […] &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You are back at square one. The &lt;code&gt;perl:5.24&lt;/code&gt; stream is not enabled, and &lt;code&gt;perl:5.26&lt;/code&gt; is the default and therefore preferred. Only the &lt;code&gt;perl-DBD-SQLite:1.58&lt;/code&gt; and &lt;code&gt;perl-DBI:1.641&lt;/code&gt; streams remained enabled, which does not matter much because those are the only streams. Nonetheless, you can reset them back using &lt;code&gt;yum module reset perl-DBI perl-DBD-SQLite&lt;/code&gt; if you like.&lt;/p&gt; &lt;h2&gt;Multicontextual streams&lt;/h2&gt; &lt;p&gt;What happened with the &lt;code&gt;DBD::SQLite&lt;/code&gt; CPAN module? It's still there and working:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ perl -MDBI -e '$dbh=DBI-&gt;connect(q{dbi:SQLite:dbname=test}); print $dbh-&gt;selectrow_array(q{SELECT bar FROM foo}), qq{\n}' Hello&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This command works because the &lt;code&gt;perl-DBD-SQLite&lt;/code&gt; module is built for both the 5.24 and 5.26 Perl versions. We call these modules &lt;em&gt;multicontextual&lt;/em&gt;. That's also the case for &lt;code&gt;perl-DBD-MySQL&lt;/code&gt; or &lt;code&gt;perl-DBI&lt;/code&gt;, but not the case for FreeRADIUS, which explains the warning you saw earlier. If you want to see these low-level details—such as which contexts are available, which dependencies are required, or which packages are contained in a module—you can use the &lt;code&gt;yum module info &lt;module&gt;:&lt;stream&gt;&lt;/code&gt; command.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;I hope this tutorial has shed some light on modules, a Red Hat Enterprise Linux 8 feature that lets you install multiple versions of software on top of one Linux platform. If you need more details, please read the &lt;a href="https://developers.redhat.com/rhel8/"&gt;documentation accompanying the product&lt;/a&gt; (namely, the userspace component management document and the &lt;a href="http://man7.org/linux/man-pages/man8/yum.8.html"&gt;yum(8) manual page&lt;/a&gt;) or ask the support team for help.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/03/10/modular-perl-red-hat-enterprise-linux-8" title="Modular Perl in Red Hat Enterprise Linux 8"&gt;Modular Perl in Red Hat Enterprise Linux 8&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Petr Pisar</dc:creator><dc:date>2022-03-10T07:00:00Z</dc:date></entry><entry><title type="html">Devoxx UK 2022 - Designing Your Best Architecture Diagrams (accepted)</title><link rel="alternate" href="http://www.schabell.org/2022/03/devoxxuk-2022-designing-best-architecture-diagrams-accepted.html" /><author><name>Eric D. Schabell</name></author><id>http://www.schabell.org/2022/03/devoxxuk-2022-designing-best-architecture-diagrams-accepted.html</id><updated>2022-03-10T06:00:00Z</updated><content type="html">As mentioned previously, I've pushed a few talks to the  conference being held from 11-13 of May in London. The Devoxx series is well know and I've attended and spoken at multiple sessions for the Belgian version in the past. It's very developer centric with a lot of good depth and knowledgable attendees. The selection committee decided that the workshop I submitted would fit their developer tools and productivity theme nicely so I'll be sharing this great material with you in London. We've been hosting and customising this open source diagram tooling for over four years now and it's gained quite a bit of traction for those interested in designing their own architectural diagrams without the complexity of learning a grand tooling layout.  We can get you started in just 30 minutes with this session! Diagraming is one of the most important communication tools for sharing your project and architectural ideas to your colleagues and teams. In this workshop walkthrough, attendees are exposed to an open source tool we host online for designing architecture diagrams like an expert. Attendees are walked through the following in just 30 mins: * open and explore the tooling in your favourite web browser * explore the provided asset libraries for drag-and-drop designing * learn about the three types of diagrams that make up a good design * create your first simple logical diagram * create your first simple schematic diagram * create a detailed diagram * how to export and import diagrams and elements from a diagram This session is an introduction to the free online workshop available for attendees to jump right into after the session. Each of the individual labs in this workshop are stand alone, allowing the attendee to focus on anything of interest without having to work through the previous labs. If you're looking to become more proficient in sharing your ideas, architectures, and projects visually to wider audiences you can't underestimate the value of a good diagram. Join us to learn the tips and tricks that make a good diagram such a good communication vehicle and how our tooling eases your design tasks. Then head homewards with a free online workshop just waiting for you to explore! (Architecture - Tools-in-Action) Really looking forward to seeing you all again in person, so join us in May for Devoxx UK in London!</content><dc:creator>Eric D. Schabell</dc:creator></entry><entry><title type="html">Content Based Routing with Quarkus and Kogito</title><link rel="alternate" href="https://blog.kie.org/2022/03/content-based-routing-with-quarkus-and-kogito.html" /><author><name>Matteo Mortari</name></author><id>https://blog.kie.org/2022/03/content-based-routing-with-quarkus-and-kogito.html</id><updated>2022-03-09T13:22:20Z</updated><content type="html">This is a second iteration of a , where we implemented EIP patterns using just Drools and Apache Camel. In this post instead, I want to share with you how to implement a complete, end-to-end Content Based Routing solution using as a developer platform, including: , , , and Apache Kafka as our message broker. I will make use of a Managed Service offering for Kafka, which you can try for free yourself too, by using this link: . I will also make use of the Red Hat Developer OpenShift Sandbox to deploy the application; you can try for free yourself by using this link: . CONTENT BASED ROUTING OVERVIEW Here is the revised Enterprise Integration Pattern diagram of the flow, with the new components: EIP Diagram of the Content Based Routing application The application keep the focus on routing healthcare-related messages; for this demo example, messages are routed accordingly to the following decision table rules: Message Routing rules in a DMN decision table The table above describes the rules of message routing in terms of the (business) domain model: * the sending application * the type of message * the type of event For the purpose of this demo, the examples are provided using HL7v2 as the technical format for the message payload. You can read more about HL7v2 on the and on this . In order to properly translate from the specific technical format HL7v2 into the domain model, we can make use of the AtlasMap capabilities of data-mapping. This allows the stakeholder involved in the content based routing application to more easily inspect and describe the rules, for instance. Here is a visual summary of the AltasMap intent combined with the DMN decision table: Using AltasMap in combination with a DMN decision table In a about data enhancement, I hinted at combining the capabilities of AltasMap with DMN; I hope this tutorial now provides a very pragmatic example! TECHNICAL DETAILS In this section, I want to highlight how the allows to implement the EIP pattern very easily: from("direct:hl7") .enrich("direct:label", aggregationStrategy) .to("log:org.drools.demo?level=DEBUG&amp;amp;showAll=true&amp;amp;multiline=true") .routingSlip(header("whereTo")) .transform(HL7.ack()) ; from("direct:label") .unmarshal().hl7() .to("atlasmap:atlasmap-mapping.adm").unmarshal().json() .process(kogitoDMNEvaluate) // &lt;== Rules as DMN decisions .setHeader("topicsHeader", simple("${body[topic names]}")) ; As you can see, that’s all needed in order to implement the Enterprise Integration Pattern in a Quarkus application, and integrate it with AltasMap and Kogito. You can access the source code at this git repository: . DEPLOYMENT After setting up the Managed Kafka and OpenShift Sandbox accounts using the links provided above, the deployment is pretty straightforward. First, we create the intended Kafka topics on the Managed Kafka console. Creating the topic (queues) in the Managed Kafka Second, we deploy the content based routing Quarkus application using the OpenShift console. The content based routing application now deployed on OpenShift Don’t forget you can easily recreate the same setup yourself and for free, by using the links provided earlier in this post. For instance, I used the very same links myself in order to make sure the demo worked fine using free resources only. Finally, the deployment and setup is complete, and we can start to make use of our content based routing solution, by sending REST calls to the ingress endpoint; this can be used as a classic webhook or analogous to a . Invoking the REST API with an EDI message payload in HL7v2 format, and it is routed to the correct queue CONCLUSIONS To see a demonstration of this setup in action, don’t forget to check out the video linked at the beginning of this post! For example, the video shows the application responding live to the incoming messages in order to route them to the expected Kafka topic. Finally, I hope this article is helpful to you as a pragmatic example on how to implement a complete content based routing solution using Quarkus, Drools DMN and Apache Camel. Feedback? Questions? Don’t hesitate to let us know! The post appeared first on .</content><dc:creator>Matteo Mortari</dc:creator></entry><entry><title>Test GitHub projects with GitHub Actions and Testing Farm</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/03/09/test-github-projects-github-actions-and-testing-farm" /><author><name>Petr Hracek, Zuzana Miklankova</name></author><id>a7128059-ac74-4a72-90e3-95abcd91db53</id><updated>2022-03-09T07:00:00Z</updated><published>2022-03-09T07:00:00Z</published><summary type="html">&lt;p&gt;Every project on GitHub that's destined for &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt; (RHEL), Fedora, or CentOS should be tested before its changes are synced into a Git distribution repository (&lt;code&gt;dist-git&lt;/code&gt;). It's important to catch problems before delivering software to customers, and help quality assurance teams catch errors.&lt;/p&gt; &lt;p&gt;&lt;a href="https://docs.testing-farm.io/general/0.1/index.html"&gt;Testing Farm&lt;/a&gt; is an open source testing system offered as a service. Testing Farm’s idea is similar to &lt;a href="https://en.wikipedia.org/wiki/Compile_farm"&gt;Compile Farms&lt;/a&gt;, but with a focus on executing automated tests. Its mission is to provide a reliable and scalable service for executing automated tests from various users, such as Fedora CI, RHEL CI, Packit, and others. The entry point for our users is an &lt;a href="http://api.dev.testing-farm.io"&gt;HTTP-based API&lt;/a&gt;. Testing Farm scales across various infrastructures, including private and public clouds.&lt;/p&gt; &lt;p&gt;The &lt;a href="https://developers.redhat.com/products/softwarecollections/overview"&gt;Red Hat Software Collections&lt;/a&gt; team has developed a way that you can use our Testing Farm in upstream GitHub repositories. Keep reading to learn how to use Testing Farm to improve your project with &lt;em&gt;internal&lt;/em&gt; tests and catch errors before products are delivered to customers.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: This article assumes you are familiar with using GitHub Actions.&lt;/p&gt; &lt;h2&gt;Get started with Testing Farm and GitHub Actions&lt;/h2&gt; &lt;p&gt;Testing Farm has an &lt;a href="https://testing-farm.gitlab.io/api/"&gt;HTTP-based API&lt;/a&gt; that you use to manage testing jobs. Connecting to the Testing Farm API requires two (on demand) artifacts:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;A Testing Farm API key, either for public or private clouds or both&lt;/li&gt; &lt;li&gt;A URL for Testing Farm requests&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;To get the API key and request URL, see the Testing Farm &lt;a href="https://docs.testing-farm.io/general/0.1/onboarding.html"&gt;onboarding document&lt;/a&gt;. Once you've acquired these artifacts, &lt;a href="https://docs.github.com/en/actions/security-guides/encrypted-secrets"&gt;save them to your GitHub repository's secrets&lt;/a&gt; so they can be used correctly within GitHub Actions.&lt;/p&gt; &lt;p&gt;The minimal steps for configuring a GitHub Action for running tests in Testing Farm are as follows:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Write a Test Management Tool/Flexible Metadata Format (TMT/FMF) &lt;a href="https://tmt.readthedocs.io/en/stable/spec/plans.html"&gt;testing plan&lt;/a&gt; for working with Testing Farm&lt;/li&gt; &lt;li&gt;Write a GitHub Action that: &lt;ul&gt;&lt;li&gt;Specifies when to run&lt;/li&gt; &lt;li&gt;Creates user request for Testing Farm&lt;/li&gt; &lt;li&gt;Gets the test results&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;/ol&gt;&lt;h2&gt;Writing TMT/FMF plans&lt;/h2&gt; &lt;p&gt;Testing Farm requires TMT/FMF plans for executing its tests. You will need to provide information about the provisioned machine and prepare that machine before running the tests.&lt;/p&gt; &lt;p&gt;The TMT plan will be uploaded to the Testing Farm machine during the process of the GitHub Action and then be executed directly from it. The plan will prepare a proper test environment and call the specific command for starting the tests. Here's an example of a TMT plan:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; summary: TMT/TFT plan for running tests on CentOS 7 description: | Run tests on CentOS-7 discover: how: shell tests: - name: Run tests on CentOS-7 framework: shell test: cd /tmp/$REPO_NAME &amp;&amp; &lt;call test suite&gt; duration: 3h prepare: how: shell script: | # TODO install packages needed for tests git clone $REPO_URL /tmp/$REPO_NAME cd /tmp/$REPO_NAME git fetch origin +refs/pull/*:refs/remotes/origin/pr/* git checkout origin/pr/$PR_NUMBER/head git submodule update --init execute: how: tmt&lt;/code&gt; &lt;/pre&gt; &lt;p&gt;Environment variables used in the TMT plan will be explicitly delivered to the Testing Farm later in the GitHub Action.&lt;/p&gt; &lt;p&gt;You can find more details on how to write TMT plans in &lt;a href="https://tmt.readthedocs.io/en/stable/spec/plans.html"&gt;the official documentation&lt;/a&gt;. The Software Collections team's &lt;a href="https://github.com/sclorg/sclorg-testing-farm"&gt;source file repository&lt;/a&gt; contains illustrative examples of TMT/FMF testing plans for &lt;a href="https://github.com/sclorg/sclorg-testing-farm/blob/main/plans/centos7.fmf"&gt;CentOS 7&lt;/a&gt;, &lt;a href="https://github.com/sclorg/sclorg-testing-farm/blob/main/plans/fedora.fmf"&gt;Fedora&lt;/a&gt;, and &lt;a href="https://github.com/sclorg/sclorg-testing-farm/blob/main/plans/c9s.fmf"&gt;CentOS Stream 9&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Write the GitHub Action&lt;/h2&gt; &lt;p&gt;As noted, the TMT plan executes tests in the Testing Farm environment. However, you still need a way to let Testing Farm know specifically when a test should be run. For this, you need to send an HTTP POST request to Testing Farm’s API; the request can be supplied directly from within the GitHub Action.&lt;/p&gt; &lt;p&gt;A GitHub Action used in this way maintains continuity of its execution with the user’s activity in the GitHub repository—a pull request, commit, or branch merging, for instance.&lt;/p&gt; &lt;h2&gt;Run tests on explicit user request&lt;/h2&gt; &lt;p&gt;This approach triggers tests at Testing Farm by commenting with specific text on a pull request. In this example, the text is the string &lt;code&gt;[test]&lt;/code&gt;. Only upstream project owners or members are authorized to trigger the tests:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; name: upstream tests at Testing Farm on: issue_comment: types: -created jobs: build: name: A job run on explicit user request run-ons: ubuntu-20.04 if: | github.event.issue.pull_request &amp;&amp; contains(github.event.comment.body, '[test]') &amp;&amp; contains(fromJson('["OWNER", "MEMBER"]'), github.event.comment.author_association) &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Triggering a test&lt;/h2&gt; &lt;p&gt;Testing Farm expects POST HTTP JSON requests as input. To handle this in a GitHub Action, install the &lt;code&gt;curl&lt;/code&gt; utility on the machine where the action will execute, along with the &lt;code&gt;jq&lt;/code&gt; utility for parsing JSON responses:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; - name: Schedule a test on Testing Farm id: sched_test run: | # Update ubuntu-20.04 in order to install curl and jq sudo apt update &amp;&amp; sudo apt -y install curl jq &lt;/code&gt; &lt;/pre&gt; &lt;p&gt;The JSON code in the request specifies the environment variables that you want to set in the Testing Farm environment. You also need to provide the &lt;code&gt;API_KEY&lt;/code&gt; and path to the TMT plan, as shown in the following listing. The request is then sent to a Testing Farm requests URL:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; - name: Schedule a test on Testing Farm id: sched_test run: | cat &lt;&lt; EOF &gt; request.json { "api_key": "${{ secrets.API_KEY }}", "test": {"fmf": { "url": "&lt;URL_TO_TMT_FMF_plan&gt;", "ref": "master", "name": "centos7" }}, "environments": [{ "arch": "x86_64", "os": {"compose": "CentOS-7"}, "variables": { "REPO_URL": "$GITHUB_SERVER_URL/$GITHUB_REPOSITORY", "REPO_NAME": "$GITHUB_REPOSITORY", "PR_NUMBER": "${{ github.event.comment.issue_url }}", "TEST_NAME": "test" } }] } EOF curl ${{ secrets.TF_ENDPOINT }}/requests --data @request.json --header "Content-Type: application/json" --output response.json &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The job ID will be embedded in the HTTP response from Testing Farm, which you can parse from the JSON and later use to query the results:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; # Store REQ_ID into outputs for later on usage req_id=$(jq -r .id response.json) echo "REQ_ID=$req_id" &gt;&gt; $GITHUB_ENV &lt;/code&gt; &lt;/pre&gt; &lt;h2&gt;Get the test results&lt;/h2&gt; &lt;p&gt;You can periodically request the state of your current test job from Testing Farm. The status request is an HTTP GET pointing to the Testing Farm URL endpoint—specifically, to &lt;code&gt;REQ_ID&lt;/code&gt;, which you stored in the previous step:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; curl ${{ secrets.TF_ENDPOINT }}/requests/${{ env.REQ_ID }} &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;When the job is completed, this information is stored in the value of the &lt;code&gt;state&lt;/code&gt; key. The final test result can be parsed from the &lt;code&gt;result&lt;/code&gt; key value.&lt;/p&gt; &lt;p&gt;Test logs can be gathered &lt;a href="http://artifacts.dev.testing-farm.io"&gt;within the job ID directory&lt;/a&gt; at testing-farm.io. Test results can be displayed as a status directly within a pull request with the &lt;a href="https://docs.github.com/en/rest/reference/repos#statuses"&gt;GitHub status API&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Run the test suite on Testing Farm&lt;/h2&gt; &lt;p&gt;At this point, you know how to set up everything you need to execute a test on Testing Farm infrastructure directly from a GitHub repository.&lt;/p&gt; &lt;p&gt;A full Testing Farm/GitHub Actions scheme example like the one described in this article can be found in the &lt;a href="https://github.com/sclorg/.github/blob/main/workflow-templates/docker-tests.yml"&gt; GitHub repository for the Software Collections team&lt;/a&gt;. This GitHub Action runs tests on Fedora, CentOS 7, CentOS Stream 9, RHEL 7, and RHEL 8. The action requires that the tested repository has access to the Testing Farm API and request URL, stored as GitHub secrets. The &lt;code&gt;GITHUB_TOKEN&lt;/code&gt; secret is necessary to connect to the GitHub API.&lt;/p&gt; &lt;p&gt;Testing Farm machines are situated within the Red Hat infrastructure, in case you are using Testing Farm private clouds. Therefore, all tests running on those machines must be checked for vulnerabilities and potentially dangerous behavior. Consequently, you should be sure to check the code in pull requests carefully from the role of owner or member.&lt;/p&gt; &lt;p&gt;Once you review the pull request, assuming you don't catch any problems or find any incorrect code, you can write a comment into the pull request containing the string &lt;code&gt;[test]&lt;/code&gt;. Submitting this string triggers the tests.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Important note:&lt;/strong&gt; This article has described how to set up the GitHub Action so that only the owner or a member of the GitHub organization can trigger the tests, a constraint we introduced for security reasons.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;The combination of GitHub Actions and the Testing Farm environment provides a robust and easy-to-configure testing platform. By using GitHub Actions, you can automate responses to activity in a GitHub repository and straightforwardly display test results directly in the same repository.&lt;/p&gt; &lt;p&gt;Testing Farm has an infrastructure of machines available on request, incorporating RHEL, CentOS, and Fedora distributions with wide configuration options adjustable for any use case. Bringing those features together offers developers and testers a great opportunity to detect defects before they enter the product codebase.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/03/09/test-github-projects-github-actions-and-testing-farm" title="Test GitHub projects with GitHub Actions and Testing Farm"&gt;Test GitHub projects with GitHub Actions and Testing Farm&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Petr Hracek, Zuzana Miklankova</dc:creator><dc:date>2022-03-09T07:00:00Z</dc:date></entry><entry><title type="html">Quarkus 2.7.4.Final released - Maintenance release</title><link rel="alternate" href="https://quarkus.io/blog/quarkus-2-7-4-final-released/" /><author><name>Guillaume Smet</name></author><id>https://quarkus.io/blog/quarkus-2-7-4-final-released/</id><updated>2022-03-09T00:00:00Z</updated><content type="html">We just released Quarkus 2.7.4.Final with a new round of bugfixes and documentation improvements. It is a safe upgrade for anyone already using 2.7. If you are not using 2.7 already, please refer to the 2.7 migration guide. Full changelog You can get the full changelog of 2.7.4.Final on GitHub....</content><dc:creator>Guillaume Smet</dc:creator></entry><entry><title>Inject custom JDK Flight Recorder events in containerized applications</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/03/08/inject-custom-jdk-flight-recorder-events-containerized-applications" /><author><name>Joshua Matsuoka</name></author><id>2f93526b-b0bf-4b62-8ec7-fd81a52c8f63</id><updated>2022-03-08T07:00:00Z</updated><published>2022-03-08T07:00:00Z</published><summary type="html">&lt;p&gt;The JDK Mission Control (JMC) agent is a powerful tool that allows users to inject custom JDK Flight Recorder (JFR) events at runtime without needing to restart the &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt; virtual machine. Just as the JMC agent plugin simplifies the process of using the agent in a non-containerized environment, the Cryostat agent plugin does the same for &lt;a href="https://developers.redhat.com/topics/containers"&gt;containerized&lt;/a&gt; environments.&lt;/p&gt; &lt;p&gt;JMC agent support is now merged into Cryostat, and Cryostat supports various API handlers for using the JMC agent in a containerized environment. This article introduces the Cryostat agent and its API handlers.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note:&lt;/strong&gt; To get up to speed on the technologies discussed in this article, check out &lt;a href="https://developers.redhat.com/articles/2021/11/16/jvm-performance-monitoring-jmc-agent"&gt;JVM performance monitoring with JMC agent&lt;/a&gt; and &lt;a href="https://developers.redhat.com/blog/2021/01/25/introduction-to-containerjfr-jdk-flight-recorder-for-containers"&gt;Introduction to Cryostat: JDK Flight Recorder for containers&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Prerequisites and setup&lt;/h2&gt; &lt;p&gt;Cryostat agent support is available from the Cryostat project's upstream repository. To get started, pull and build the most recent version:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; $ git clone https://github.com/cryostatio/cryostat $ cd cryostat $ mvn clean verify &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Once it's been built, you can run a demo instance of Cryostat via the &lt;code&gt;smoketest&lt;/code&gt; script:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; $ smoketest.sh &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In order to use the JMC agent integration with Cryostat, you must ensure that its JAR is present in the same container as the application. Then, run the application with the &lt;code&gt;javaagent&lt;/code&gt; flag specifying the JAR:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; -javaagent:target/org.openjdk.jmc.agent-1.0.0-SNAPSHOT.jar &lt;/code&gt;&lt;/pre&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note:&lt;/strong&gt; You can download the JMC agent from &lt;a href="https://github.com/adoptium/jmc-overrides/releases"&gt;Adoptium's JMC overrides releases&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Using the Cryostat JMC agent integration&lt;/h2&gt; &lt;p&gt;The Cryostat agent offers a set of API handlers that interact with the JMC agent and manage templates for custom events. The &lt;code&gt;ProbeTemplate&lt;/code&gt; handlers allow users to post or delete probe templates. These templates are XML files that describe the custom events to be injected; they are stored with Cryostat and can be applied to any valid targets with the agent running, or deleted when they are no longer needed. Similarly, the &lt;code&gt;TargetProbePost&lt;/code&gt;, &lt;code&gt;Delete&lt;/code&gt;, and &lt;code&gt;Get&lt;/code&gt; handlers facilitate adding, removing, and retrieving custom event configurations from target JVMs.&lt;/p&gt; &lt;h3&gt;Custom event monitoring&lt;/h3&gt; &lt;p&gt;For an example workflow, suppose the Cryostat agent is currently running with Cryostat itself as the target application. Now, you want to add custom events to Cryostat to monitor how it's running. To start, you need a probe template to work with, so consider the following:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; &lt;jfragent&gt; &lt;!-- Global configuration options --&gt; &lt;config&gt; &lt;!-- This is the prefix to use when generating event class names. --&gt; &lt;classprefix&gt;__JFREvent&lt;/classprefix&gt; &lt;!-- Will allow the recording of arrays and object parameters as Strings. This will cause toString to be called for array elements and objects other than strings, which in turn can cause trouble if the toString method is badly implemented. Use with care. --&gt; &lt;allowtostring&gt;true&lt;/allowtostring&gt; &lt;!-- Allows converters to be used. See the org.openjdk.jmc.agent.converters package for more information. --&gt; &lt;allowconverter&gt;true&lt;/allowconverter&gt; &lt;/config&gt; &lt;events&gt; &lt;event id="demo.cryostat.jfr"&gt; &lt;label&gt;CryostatDemoEvent&lt;/label&gt; &lt;description&gt;Event for the agent plugin demo&lt;/description&gt; &lt;path&gt;demo&lt;/path&gt; &lt;stacktrace&gt;true&lt;/stacktrace&gt; &lt;class&gt;io.cryostat.net.web.http.generic.HealthGetHandler&lt;/class&gt; &lt;method&gt; &lt;name&gt;handle&lt;/name&gt; &lt;descriptor&gt;(io/vertx/ext/web/RoutingContext;)V&lt;/descriptor&gt; &lt;/method&gt; &lt;!-- location {ENTRY, EXIT, WRAP}--&gt; &lt;location&gt;ENTRY&lt;/location&gt; &lt;/event&gt; &lt;/events&gt; &lt;/jfragent&gt; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This is a simple configuration that adds a custom event to the entry point of the &lt;code&gt;handle&lt;/code&gt; method. Once injected, this configuration will emit a custom &lt;code&gt;CryostatDemoEvent&lt;/code&gt; every time the &lt;code&gt;handle&lt;/code&gt; method is called.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;&lt;config&gt;&lt;/code&gt; section of the template determines the prefix used for the custom event classes, as well as whether any advanced functionality is required. The Cryostat agent supports the capture of fields and method parameters to be emitted with the event. It then utilizes user-defined converter methods to convert those fields and parameters into content types that JDK Flight Recorder can use. However, this functionality must be specifically enabled in the &lt;code&gt;&lt;config&gt;&lt;/code&gt; section.&lt;/p&gt; &lt;p&gt;Following the &lt;code&gt;&lt;config&gt;&lt;/code&gt; section, you can specify any number of events to be injected, you only need to provide an event ID, label, and description. The &lt;code&gt;&lt;path&gt;&lt;/code&gt; element corresponds to the path that the event will appear under when viewed in a graphical tool like JDK Mission Control. The &lt;code&gt;&lt;stacktrace&gt;&lt;/code&gt; element determines if stack traces should be recorded with the event.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;&lt;class&gt;&lt;/code&gt;, &lt;code&gt;&lt;method&gt;&lt;/code&gt;, and &lt;code&gt;&lt;location&gt;&lt;/code&gt; elements determine precisely where the event should be injected. You must provide the formal descriptor for the method here; this takes the form: &lt;code&gt;(Parameter Descriptor*)Return Descriptor&lt;/code&gt;. For example, for the method &lt;code&gt;int isAlive()&lt;/code&gt;, the method descriptor would be &lt;code&gt;()Z&lt;/code&gt;. See the &lt;a href="https://docs.oracle.com/javase/specs/jvms/se7/html/jvms-4.html#jvms-4.3.3"&gt;JVM specification&lt;/a&gt; for more about the method descriptor format.&lt;/p&gt; &lt;h3&gt;Injecting and recording custom events&lt;/h3&gt; &lt;p&gt;Once you have a probe template, all you need to do is send a few API requests to Cryostat to upload it and apply it to the target. (Remember that, in this case, the target is Cryostat itself.)&lt;/p&gt; &lt;pre&gt; &lt;code&gt; $ curl -F probeTemplate=@cryostat-probe.xml http://0.0.0.0:8181/api/v2/probes/ &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This first request calls out to the &lt;code&gt;ProbeTemplateUpload&lt;/code&gt; handler (&lt;code&gt;api/v2/probes&lt;/code&gt;). This handler expects the &lt;code&gt;ProbeTemplate&lt;/code&gt; to be uploaded in a form with the name &lt;code&gt;probeTemplate&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Now you just have to send one more request:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; $ curl -X POST localhost:8181/api/v2/targets/localhost/probes/cryostat-probes &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The second request calls out to the &lt;code&gt;TargetProbePost&lt;/code&gt; handler (&lt;code&gt;api/v2/targets/:targetID/probes/:probeTemplate&lt;/code&gt;). When you provide this handler with a target and a probe template, it will apply the probe template to the target, injecting the custom events. The next time a recording is run, the custom events will be recorded.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;The JMC agent is a powerful tool for creating and recording custom events without the need to manually write those events or rebuild an application. The Cryostat agent brings the same advantages to a containerized environment. With JMC agent support being merged upstream, it is now easier than ever to take advantage of these capabilities.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/03/08/inject-custom-jdk-flight-recorder-events-containerized-applications" title="Inject custom JDK Flight Recorder events in containerized applications"&gt;Inject custom JDK Flight Recorder events in containerized applications&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Joshua Matsuoka</dc:creator><dc:date>2022-03-08T07:00:00Z</dc:date></entry><entry><title type="html">Kogito 1.18.0 released!</title><link rel="alternate" href="https://blog.kie.org/2022/03/kogito-1-18-0-released.html" /><author><name>Cristiano Nicolai</name></author><id>https://blog.kie.org/2022/03/kogito-1-18-0-released.html</id><updated>2022-03-08T02:12:47Z</updated><content type="html">We are glad to announce that the Kogito 1.18.0 release is now available! This goes hand in hand with , release. From a feature point of view, we included a series of new features and bug fixes, including: * Spring Boot upgraded to version to 2.4.9 * Serverless Workflow data input schema validation * Serverless Workflow Rest Exception handler  * Serverless Workflow function reference replacement (for constraints and expressions) * Serverless Workflow magic word for retrieving process metadata ($WORKFLOW.instanceId) * Allow changing default incoming/outgoing channel name for messaging addon * Allow MessageDecorator override to set Kafka record key For more details head to the complete . All artifacts are available now: * Kogito runtime artifacts are available on Maven Central. * Kogito examples can be found . * Kogito images are available on . * Kogito operator is available in the in OpenShift and Kubernetes. * Kogito tooling 0.17.0 artifacts are available at the . A detailed changelog for 1.18.0 can be found in . New to Kogito? Check out our website . Click the "Get Started" button. The post appeared first on .</content><dc:creator>Cristiano Nicolai</dc:creator></entry></feed>
