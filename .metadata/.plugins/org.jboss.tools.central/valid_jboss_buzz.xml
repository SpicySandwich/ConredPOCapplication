<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0" uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Simplify secure connections to PostgreSQL databases with Node.js</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/03/28/simplify-secure-connections-postgresql-databases-nodejs" /><author><name>Michael Dawson</name></author><id>f045aeec-19ed-4a10-a365-a0fcbfed01d6</id><updated>2022-03-28T07:00:00Z</updated><published>2022-03-28T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://www.postgresql.org/"&gt;PostgreSQL&lt;/a&gt; is an advanced open source relational database that is commonly used by applications to store structured data. Before accessing a database, the application must connect and provide security credentials. As a &lt;a href="https://developers.redhat.com/topics/nodejs"&gt;Node.js&lt;/a&gt; developer, how can you safely share and provide those credentials in &lt;a href="https://developers.redhat.com/topics/javascript"&gt;JavaScript&lt;/a&gt; code without a lot of work? This article introduces service bindings and the &lt;a href="https://www.npmjs.com/package/kube-service-bindings"&gt;kube-service-bindings&lt;/a&gt; package, along with a convenient graphical interface in &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;When using a database, the four basic operations are create, read, update, and delete (CRUD, for short). Our team maintains an &lt;a href="https://github.com/nodeshift-starters/nodejs-rest-http-crud"&gt;example CRUD application on GitHub&lt;/a&gt; that shows how to connect to a PostgreSQL database and execute the four basic operations. We use that example to illustrate the security model in this article.&lt;/p&gt; &lt;h2&gt;Security risks when connecting to the PostgreSQL database&lt;/h2&gt; &lt;p&gt;The information you need to connect to a PostgreSQL database is:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;User&lt;/li&gt; &lt;li&gt;Password&lt;/li&gt; &lt;li&gt;Host&lt;/li&gt; &lt;li&gt;Database&lt;/li&gt; &lt;li&gt;Port&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;You definitely need to be careful about who has access to the user and password, and ideally, you don't want any of these values to be public. This section looks at some simple methods that fail to protect this sensitive information adequately.&lt;/p&gt; &lt;h3&gt;Setting environment variables explicitly&lt;/h3&gt; &lt;p&gt;Using environment variables is the easiest way to configure a connection and is often used in examples like the following JavaScript code:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-javascript"&gt;const serviceHost = process.env.MY_DATABASE_SERVICE_HOST; const user = process.env.DB_USERNAME; const password = process.env.DB_PASSWORD; const databaseName = process.env.POSTGRESQL_DATABASE const connectionString = `postgresql://${user}:${password}@${serviceHost}:5432/${databaseName}`; connectionOptions = { connectionString }; const pool = new Pool(connectionOptions);&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Unfortunately, using environment variables is not necessarily secure. If you set the environment variables from the command line, anybody with access to the environment can see them. Tools and frameworks also often make it easy to access environment variables for debugging purposes. For example, in OpenShift, you can view the environment variables from the console, as shown in Figure 1. So you need to find a way to provide connection credentials while keeping them hidden from interlopers.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/pod_0.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/pod_0.png?itok=gwHLAigv" width="824" height="642" alt="Pod details in the OpenShift console reveal the environmental variables set in the pod." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: Pod details in the OpenShift console reveal the environmental variables set in the pod.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Loading environment variables from dotenv&lt;/h3&gt; &lt;p&gt;Instead of setting the credentials in the environment directly, a safer way is to use a package such as &lt;a href="https://www.npmjs.com/package/dotenv"&gt;dotenv&lt;/a&gt; to get the credentials from a file and provide them to the Node.js application environment. The benefit of using &lt;code&gt;dotenv&lt;/code&gt; is that the credentials don't show up in the environment outside of the Node.js process.&lt;/p&gt; &lt;p&gt;Although this approach is better, the credentials still might be exposed if you dump the Node.js environment for debugging through a &lt;a href="https://developer.ibm.com/articles/easily-identify-problems-in-your-nodejs-apps-with-diagnostic-report/"&gt;Node.js diagnostic report&lt;/a&gt;. You are also left with the question of how to get the &lt;code&gt;dotenv&lt;/code&gt; file securely to the application. If you are deploying to &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt;, you can map a file into deployed &lt;a href="https://developers.redhat.com/topics/containers/"&gt;containers&lt;/a&gt;, but that will take some planning and coordination for deployments.&lt;/p&gt; &lt;p&gt;By this point, you are probably thinking that this seems like a lot of work and are wondering whether you need to configure the connection information for each type of service and set of credentials that are needed by an application. The good news is that for Kubernetes environments, this problem has already been solved. We cover the solution, service binding, in the next section.&lt;/p&gt; &lt;h2&gt;Passing the credentials securely: Service binding in Kubernetes&lt;/h2&gt; &lt;p&gt;Service binding is a standard approach to map a set of files into containers to provide credentials in a safe and scalable way. You can read more about the Service Binding specification for Kubernetes on &lt;a href="https://github.com/k8s-service-bindings/spec"&gt;GitHub&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The specification does not define what files are mapped in for a given service type. In OpenShift, binding to a PostgreSQL database instance (created using either the Crunchy or the Cloud Native PostgreSQL Operators, as described in an &lt;a href="https://developers.redhat.com/articles/2021/10/27/announcing-service-binding-operator-10-ga"&gt;overview of the Service Binding Operator&lt;/a&gt;) results in mapping the following files into the application container:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ SERVICE_BINDING_ROOT/&lt;postgressql-instance-name&gt; ├── user ├── host ├── database ├── password ├── port ├── ca.crt └── tls.key └── tls.crt&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;code&gt;SERVICE_BINDING_ROOT&lt;/code&gt; is passed to the application through the environment.&lt;/p&gt; &lt;p&gt;The last three files contain the keys and certificates needed to connect over the widely used Transport Layer Security (TLS) standard and are present only if the database is configured to use TLS.&lt;/p&gt; &lt;h2&gt;Consuming service bindings easily with kube-service-bindings&lt;/h2&gt; &lt;p&gt;Now that you have the credentials available to the application running in the container, the remaining work is to read the credentials from those files and provide them to the PostgreSQL client used within your Node.js application. But wait—that still sounds like a lot of work, and it's also tied to the client you are using.&lt;/p&gt; &lt;p&gt;To make this easier, we've put together an npm package called &lt;a href="https://www.npmjs.com/package/kube-service-bindings"&gt;kube-service-bindings&lt;/a&gt;, which makes it easy for Node.js applications to consume these secrets without requiring developers to be familiar with service bindings.&lt;/p&gt; &lt;p&gt;The package provides the &lt;code&gt;getBinding()&lt;/code&gt; method, which does roughly the following:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Look for the &lt;code&gt;SERVICE_BINDING_ROOT&lt;/code&gt; variable in order to determine whether bindings are available.&lt;/li&gt; &lt;li&gt;Read the connection information from the files.&lt;/li&gt; &lt;li&gt;Map the names of the files to the option names needed by the Node.js clients that will connect to the service.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Figure 2 shows the steps.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/get.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/get.png?itok=DwFwUD5F" width="1191" height="707" alt="The getBinding() method involves three main steps." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 2: The getBinding() method involves three main steps.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Let's assume you connect to PostgreSQL using the popular &lt;a href="https://www.npmjs.com/package/pg"&gt;pg&lt;/a&gt; client, a library that provides all the basic commands to interact with the database. In this case you call the &lt;code&gt;getBinding()&lt;/code&gt; method with &lt;code&gt;POSTGRESQL&lt;/code&gt; and &lt;code&gt;pg&lt;/code&gt; to tell &lt;code&gt;kube-service-bindings&lt;/code&gt; which client the application is using, and then pass the object returned by &lt;code&gt;getBinding()&lt;/code&gt;when you create a Pool object. Minus error checking, the code is as simple as this:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-javascript"&gt;const serviceBindings = require('kube-service-bindings'); const { Pool } = require('pg'); let connectionOptions; try { connectionOptions = serviceBindings.getBinding('POSTGRESQL', 'pg'); } catch (err) { } const pool = new Pool(connectionOptions);&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The first parameter to &lt;code&gt;getBindings()&lt;/code&gt; is &lt;code&gt;POSTGRESQL&lt;/code&gt;, to specify that you are connecting to a PostgreSQL database. The second parameter, &lt;code&gt;pg&lt;/code&gt;, tells &lt;code&gt;kube-service-bindings&lt;/code&gt; that you are using the &lt;code&gt;pg&lt;/code&gt; client so that the call will return the information as an object that can be passed when creating a &lt;code&gt;pg&lt;/code&gt; Pool object.&lt;/p&gt; &lt;p&gt;The CRUD example, and more specifically the &lt;a href="https://github.com/nodeshift-starters/nodejs-rest-http-crud/blob/94cce5e4056f58511bd1b66576e64594e5ac4d4f/lib/db/index.js#L7"&gt;lib/db/index.js&lt;/a&gt; file, has been updated so that it can get the credentials from the environment, or automatically using &lt;code&gt;kube-service-bindings&lt;/code&gt; when credentials are available through service bindings.&lt;/p&gt; &lt;p&gt;With &lt;code&gt;kube-service-bindings&lt;/code&gt;, it's easy for Node.js developers to use credentials available through service bindings. The second part is to set up the service bindings themselves. The procedure is to install the Service Binding Operator as &lt;a href="https://developers.redhat.com/articles/2021/10/27/announcing-service-binding-operator-10-ga"&gt;described in the overview article&lt;/a&gt; mentioned earlier, install an Operator to help you create databases, create the database for your application, and finally apply some YAML to tell the Service Binding Operator to bind the database to your application.&lt;/p&gt; &lt;h2&gt;Setting up service bindings in OpenShift&lt;/h2&gt; &lt;p&gt;With the release of &lt;a href="https://docs.openshift.com/container-platform/4.8/release_notes/ocp-4-8-release-notes.html"&gt;OpenShift 4.8&lt;/a&gt;, you can use the OpenShift user interface (UI) to do the service binding. Thus, administrators and operators of a cluster can easily set up the PostgreSQL database instance for an organization. Developers can then connect their applications without needing to know the credentials. You can use the UI for convenience during initial development, and then YAML for more automated or production deployments.&lt;/p&gt; &lt;p&gt;The UI steps are quite simple:&lt;/p&gt; &lt;ol&gt;&lt;li&gt; &lt;p&gt;Create a database using one of the PostgresSQL Operators.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Deploy your application to the same namespace using &lt;code&gt;kube-service-bindings&lt;/code&gt;. Figure 3 shows the topology view of the namespace.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/name_0.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/name_0.png?itok=Kdcvsl97" width="600" height="244" alt="The namespace contains the PostgreSQL database and Node.js application." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 3: The namespace contains the PostgreSQL database and Node.js application.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/li&gt; &lt;li&gt; &lt;p&gt;Drag a link from the application to the database until you see the "Create a binding connector" box pop up (Figure 4).&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/bind.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/bind.png?itok=nH27ra3j" width="600" height="249" alt="Create a binding from the Node.js application to the PostgreSQL database." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 4: Create a binding from the Node.js application to the PostgreSQL database.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/li&gt; &lt;li&gt; &lt;p&gt;Finally, release the mouse button. The binding is created (Figure 5) and the credentials are automatically mapped into your application pods. If you've configured your application to retry the connection until service bindings are available, it should then get the credentials and connect to the database.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/done.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/done.png?itok=iDfeRLWt" width="600" height="266" alt="The binding is established." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 5: The binding is established.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/li&gt; &lt;/ol&gt;&lt;h2&gt;Further resources&lt;/h2&gt; &lt;p&gt;This article introduced you to the credentials needed to connect to a PostgreSQL database and how they can be safely provided to your Node.js applications. To learn more, try the following:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Install and experiment with the &lt;a href="https://github.com/nodeshift-starters/nodejs-rest-http-crud"&gt;CRUD example&lt;/a&gt; to explore the code and &lt;a href="https://www.npmjs.com/package/kube-service-bindings"&gt;kube-service-bindings&lt;/a&gt;. (If you are really adventurous, you can create your own files and set &lt;code&gt;SERVICE_BINDING_ROOT&lt;/code&gt; to point to them.)&lt;/li&gt; &lt;li&gt;Work through how to set up service bindings for a PostgreSQL database using the instructions in the &lt;a href="https://developers.redhat.com/articles/2021/10/27/announcing-service-binding-operator-10-ga"&gt;Service Binding Operator overview&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Connect the &lt;a href="https://github.com/nodeshift-starters/nodejs-rest-http-crud"&gt;CRUD example&lt;/a&gt; to the PostgreSQL database you created using the UI.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;We hope you found this article informative. To stay up to date with what else Red Hat is up to on the Node.js front, check out our &lt;a href="https://developers.redhat.com/topics/nodejs"&gt;Node.js topic page&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/03/28/simplify-secure-connections-postgresql-databases-nodejs" title="Simplify secure connections to PostgreSQL databases with Node.js"&gt;Simplify secure connections to PostgreSQL databases with Node.js&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Michael Dawson</dc:creator><dc:date>2022-03-28T07:00:00Z</dc:date></entry><entry><title type="html">Quarkus Tools for Visual Studio Code - 1.10.0 release</title><link rel="alternate" href="https://quarkus.io/blog/vscode-quarkus-1.10.0/" /><author><name>Roland Grunberg</name></author><id>https://quarkus.io/blog/vscode-quarkus-1.10.0/</id><updated>2022-03-28T00:00:00Z</updated><content type="html">Quarkus Tools for Visual Studio Code 1.10.0 has been released on the VS Code Marketplace &amp;amp; Open VSX. For a list of all changes, please refer to the changelog. It’s been about 8 months since our last release of Quarkus Tools for VS Code. 8 months!! That’s a really long...</content><dc:creator>Roland Grunberg</dc:creator></entry><entry><title type="html">Application modernization patterns with Apache Kafka, Debezium, and Kubernetes</title><link rel="alternate" href="http://www.ofbizian.com/2022/03/application-modernization-patterns-with.html" /><author><name>Unknown</name></author><id>http://www.ofbizian.com/2022/03/application-modernization-patterns-with.html</id><updated>2022-03-27T11:23:00Z</updated><content type="html">“We build our computers the way we build our cities—over time, without a plan, on top of ruins.” Ellen Ullman , but it applies just as much today to the way we build modern applications; that is, over time, with short-term plans, on top of legacy software. In this article, I will introduce a few patterns and tools that I believe work well for thoughtfully modernizing legacy applications and building modern event-driven systems. Note: If you prefer watch my talk on YouTube about which this post is  based on. APPLICATION MODERNIZATION IN CONTEXT Application modernization refers to the process of taking an existing legacy application and modernizing its infrastructure—the internal architecture—to improve the velocity of new feature delivery, improve performance and scalability, expose the functionality for new use cases, and so on. Luckily, there is already a good classification of modernization and migration types, as shown in Figure 1. Figure 1: Three modernization types and the technologies we might use for them. Depending on your needs and appetite for change, there are a few levels of modernization: * Retention: The easiest thing you can do is to retain what you have and ignore the application's modernization needs. This makes sense if the needs are not yet pressing. * Retirement: Another thing you could do is retire and get rid of the legacy application. That is possible if you discover the application is no longer being used. * Rehosting: The next thing you could do is to rehost the application, which typically means taking an application as-is and hosting it on new infrastructure such as cloud infrastructure, or even on Kubernetes through something like KubeVirt. This is not a bad option if your application cannot be containerized, but you still want to reuse your Kubernetes skills, best practices, and infrastructure to . * Replatforming: When changing the infrastructure is not enough and you are doing a bit of alteration at the edges of the application without changing its architecture, replatforming is an option. Maybe you are changing the way the application is configured so that it can be containerized, or moving from a legacy Java EE runtime to an open source runtime. Here, you could use a tool like to analyze your application and return a report with what needs to be done. * Refactoring: Much application modernization today focuses on migrating monolithic, on-premises applications to a cloud-native microservices architecture that supports faster release cycles. That involves refactoring and rearchitecting your application, which is the focus of this article. For this article, we will assume we are working with a monolithic, on-premise application, which is a common starting point for modernization. The approach discussed here could also apply to other scenarios, such as a cloud migration initiative. CHALLENGES OF MIGRATING MONOLITHIC LEGACY APPLICATIONS Deployment frequency is a common challenge for migrating monolithic legacy applications. Another challenge is scaling development so that more developers and teams can work on a common code base without stepping on each other’s toes. Scaling the application to handle an increasing load in a reliable way is another concern. On the other hand, the expected benefits from a modernization include reduced time to market, increased team autonomy on the codebase, and dynamic scaling to handle the service load more efficiently. Each of these benefits offsets the work involved in modernization. Figure 2 shows an example infrastructure for scaling a legacy application for increased load. Figure 2: Refactoring a legacy application into event-driven microservices. ENVISIONING THE TARGET STATE AND MEASURING SUCCESS For our use case, the target state is an architectural style that follows microservices principles using open source technologies such as Kubernetes, , and Debezium. We want to end up with independently deployable services modeled around a business domain. Each service should own its own data, emit its own events, and so on. When we plan for modernization, it is also important to consider how we will measure the outcomes or results of our efforts. For that purpose, we can use metrics such as lead time for changes, deployment frequency, time to recovery, concurrent users, and so on. The next sections will introduce three design patterns and three open source technologies—Kubernetes, Apache Kafka, and Debezium—that you can use to migrate from brown-field systems toward green-field, modern, event-driven services. We will start with the Strangler pattern. THE STRANGLER PATTERN The Strangler pattern is the most popular technique used for application migrations. Martin Fowler introduced and popularized this pattern under the name of , which was inspired by a type of fig that seeds itself in the upper branches of a tree and gradually evolves around the original tree, eventually replacing it. The parallel with application migration is that our new service is initially set up to wrap the existing system. In this way, the old and the new systems can coexist, giving the new system time to grow and potentially replace the old system. Figure 3 shows the main components of the Strangler pattern for a legacy application migration. Figure 3: The Strangler pattern in a legacy application migration. The key benefit of the Strangler pattern is that it allows low-risk, incremental migration from a legacy system to a new one. Let’s look at each of the main steps involved in this pattern. STEP 1: IDENTIFY FUNCTIONAL BOUNDARIES The very first question is where to start the migration. Here, we can use domain-driven design to help us identify aggregates and the bounded contexts where each represents a potential unit of decomposition and a potential boundary for microservices. Or, we can use the technique created by Antonio Brandolini to gain a shared understanding of the domain model. Other important considerations here would be how these models interact with the database and what work is required for database decomposition. Once we have a list of these factors, the next step is to identify the relationships and dependencies between the bounded contexts to get an idea of the relative difficulty of the extraction. Armed with this information, we can proceed with the next question: Do we want to start with the service that has the least amount of dependencies, for an easy win, or should we start with the most difficult part of the system? A good compromise is to pick a service that is representative of many others and can help us build a good technology foundation. That foundation can then serve as a base for estimating and migrating other modules. STEP 2: MIGRATE THE FUNCTIONALITY For the strangler pattern to work, we must be able to clearly map inbound calls to the functionality we want to move. We must also be able to redirect these calls to the new service and back if needed. Depending on the state of the legacy application, client applications, and other constraints, weighing our options for this interception might be straightforward or difficult: * The easiest option would be to change the client application and redirect inbound calls to the new service. Job done. * If the legacy application uses HTTP, then we’re off to a good start. HTTP is very amenable to redirection and we have a wealth of transparent proxy options to choose from. * In practice, it likely that our application will not only be using REST APIs, but will have SOAP, FTP, RPC, or some kind of traditional messaging endpoints, too. In this case, we may need to build a custom protocol translation layer with something like . Interception is a potentially dangerous slippery slope: If we start building a custom protocol translation layer that is shared by multiple services, we risk adding too much intelligence to the shared proxy that services depend on. This would move us away from the "” mantra. A better option is to use the , illustrated in Figure 4. Figure 4: The Sidecar pattern. Rather than placing custom proxy logic in a shared layer, make it part of the new service. But rather than embedding the custom proxy in the service at compile-time, we use the and make the proxy a runtime binding activity. With this pattern, legacy clients use the protocol-translating proxy and new clients are offered the new service API. Inside the proxy, calls are translated and directed to the new service. That allows us to reuse the proxy if needed. More importantly, we can easily decommission the proxy when it is no longer needed by legacy clients, with minimal impact on the newer services. STEP 3: MIGRATE THE DATABASE Once we have identified the functional boundary and the interception method, we need to decide how we will approach database strangulation—that is, separating our legacy database from application services. We have a few paths to choose from. DATABASE FIRST In a database-first approach, we separate the schema first, which could potentially impact the legacy application. For example, a SELECT might require pulling data from two databases, and an UPDATE can lead to the need for distributed transactions. This option requires changes to the source application and doesn’t help us demonstrate progress in the short term. That is not what we are looking for. CODE FIRST A code-first approach lets us get to independently deployed services quickly and reuse the legacy database, but it could give us a false sense of progress. Separating the database can turn out to be challenging and hide future performance bottlenecks. But it is a move in the right direction and can help us discover the data ownership and what needs to be split into the database layer later. CODE AND DATABASE TOGETHER Working on the code and database together can be difficult to aim for from the get-go, but it is ultimately the end state we want to get to. Regardless of how we do it, we want to end up with a separate service and database; starting with that in mind will help us avoid refactoring later.   Figure 4.1: Database strangulation strategies Having a separate database requires data synchronization. Once again, we can choose from a few common technology approaches. TRIGGERS Most databases allow us to execute custom behavior when data is changed. In some cases, that could even be calling a web service and integrating with another system. But how triggers are implemented and what we can do with them varies between databases. Another significant drawback here is that using triggers requires changing the legacy database, which we might be reluctant to do. QUERIES We can use queries to regularly check the source database for changes. The changes are typically detected with implementation strategies such as timestamps, version numbers, or status column changes in the source database. Regardless of the implementation strategy, polling always leads to the dilemma between polling often and creating overhead over the source database, or missing frequent updates. While queries are simple to install and use, this approach has significant limitations. It is unsuitable for mission-critical applications with frequent database interactions. LOG READERS Log readers identify changes by scanning the database transaction log files. Log files exist for database backup and recovery purposes and provide a reliable way to capture all changes including DELETEs. Using log readers is the least disruptive option because they require no modification to the source database and they don’t have a query load. The main downside of this approach is that there is no common standard for the transaction log files and we'll need specialized tools to process them. This is where Debezium fits in.   Figure 4.2: Data synchronization patterns Before moving on to the next step, let's see how using Debezium with the log reader approach works. CHANGE DATA CAPTURE WITH DEBEZIUM When an application writes to the database, changes are recorded in log files, then the database tables are updated. For MySQL, the log file is binlog; for PostgreSQL, it is the write-ahead-log; and for MongoDB it's the op log. The good news is Debezium has connectors for different databases, so it does the hard work for us of understanding the format of all of these log files. Debezium can read the log files and produce a generic abstract event into a messaging system such as Apache Kafka, which contains the data changes. Figure 5 shows Debezium connectors as the interface for a variety of databases. Figure 5: Debezium connectors in a microservices architecture. Debezium is the most widely used open source change data capture (CDC) project with and features that make it a great fit for the Strangler pattern. WHY IS DEBEZIUM A GOOD FIT FOR THE STRANGLER PATTERN? One of the most important reasons to consider the Strangler pattern for migrating monolithic legacy applications is reduced risk and the ability to fall back to the legacy application. Similarly, Debezium is completely transparent to the legacy application, and it doesn’t require any changes to the legacy data model. Figure 6 shows Debezium in an example microservices architecture. Figure 6: Debezium deployment in a hybrid-cloud environment. With a minimal configuration to the legacy database, we can capture all the required data. So at any point, we can remove Debezium and fall back to the legacy application if we need to. DEBEZIUM FEATURES THAT SUPPORT LEGACY MIGRATIONS Here are some of Debezium's specific features that support migrating a monolithic legacy application with the Strangler pattern: * Snapshots: Debezium can take a snapshot of the current state of the source database, which we can use for bulk data imports. Once a snapshot is completed, Debezium will start streaming the changes to keep the target system in sync. * Filters: Debezium lets us pick which databases, tables, and columns to stream changes from. With the Strangler pattern, we are not moving the whole application. * Single message transformation (SMT): This feature can act like an anti-corruption layer and protect our new data model from legacy naming, data formats, and even let us filter out obsolete data * Using Debezium with a schema registry: We can use a schema registry such as with Debezium for schema validation, and also use it to enforce version compatibility checks when the source database model changes. This can prevent changes from the source database from impacting and breaking the new downstream message consumers. * Using Debezium with Apache Kafka: There are many reasons why Debezium and Apache Kafka work well together for application migration and modernization. Guaranteed ordering of database changes, message compaction, the ability to re-read changes as many times as needed, and tracking transaction log offsets are all good examples of why we might choose to use these tools together. STEP 4: RELEASING SERVICES With that quick overview of Debezium, let’s see where we are with the Strangler pattern. Assume that, so far, we have done the following: * Identified a functional boundary. * Migrated the functionality. * Migrated the database. * Deployed the service into a Kubernetes environment. * Migrated the data with Debezium and kept Debezium running to synchronize ongoing changes. At this point, there is not yet any traffic routed to the new services, but we are ready to release the new services. Depending on our routing layer's capabilities, we can use techniques such as dark launching, parallel runs, and canary releasing to reduce or remove the risk of rolling out the new service, as shown in Figure 7. Figure 7: Directing read traffic to the new service. What we can also do here is to only direct read requests to our new service initially, while continuing to send the writes to the legacy system. This is required as we are replicating changes in a single direction only. When we see that the read operations are going through without issues, we can then direct the write traffic to the new service. At this point, if we still need the legacy application to operate for whatever reason, we will need to stream changes from the new services toward the legacy application database. Next, we'll want to stop any write or mutating activity in the legacy module and stop the data replication from it. Figure 8 illustrates this part of the pattern implementation. Figure 8: Directing read and write traffic to the new service. Since we still have legacy read operations in place, we are continuing the replication from the new service to the legacy application. Eventually, we'll stop all operations in the legacy module and stop the data replication. At this point, we will be able to decommission the migrated module. We've had a broad look at using the Strangler pattern to migrate a monolithic legacy application, but we are not quite done with modernizing our new microservices-based architecture. Next, let’s consider some of the challenges that come later in the modernization process and how Debezium, Apache Kafka, and Kubernetes might help. AFTER THE MIGRATION: MODERNIZATION CHALLENGES The most important reason to consider using the Strangler pattern for migration is the reduced risk. This pattern gives value steadily and allows us to demonstrate progress through frequent releases. But migration alone, without enhancements or new “business value” can be a hard sell to some stakeholders. In the longer-term modernization process, we also want to enhance our existing services and add new ones. With modernization initiatives, very often, we are also tasked with setting the foundation and best practices for building modern applications that will follow. By migrating more and more services, adding new ones, and in general by transitioning to the microservices architecture, new challenges will come up, including the following: * Automating the deployment and operating a large number of services. * Performing dual-writes and orchestrating long-running business processes in a reliable and scalable manner. * Addressing the analytical and reporting needs. There are all challenges that might not have existed in the legacy world. Let’s explore how we can address a few of them using a combination of design patterns and technologies. CHALLENGE 1: OPERATING EVENT-DRIVEN SERVICES AT SCALE While peeling off more and more services from the legacy monolithic application, and also creating new services to satisfy emerging business requirements, the need for automated deployments, rollbacks, placements, configuration management, upgrades, self-healing becomes apparent. These are the exact features that make Kubernetes a great fit for operating large-scale microservices. Figure 9 illustrates. Figure 9: A sample event-driven architecture on top of Kubernetes. When we are working with event-driven services, we will quickly find that we need to automate and integrate with an event-driven infrastructure—which is where Apache Kafka and other projects in its ecosystem might come in. Moreover, we can use to help automate the management of Kafka and the following supporting services: * provides an Operator for managing Apicurio Schema Registry on Kubernetes. * offers Operators for managing Kafka and Kafka Connect clusters declaratively on Kubernetes. * (Kubernetes Event-Driven Autoscaling) offers workload auto-scalers for scaling up and down services that consume from Kafka. So, if the consumer lag passes a threshold, the Operator will start more consumers up to the number of partitions to catch up with message production. * offers event-driven abstractions backed by Apache Kafka. Note: Kubernetes not only provides a target platform for application modernization but also allows you to grow your applications on top of the same foundation into a large-scale event-driven architecture. It does that through automation of user workloads, Kafka workloads, and other tools from the Kafka ecosystem. That said, not everything has to run on your Kubernetes. For example, you can use a or a schema registry service from Red Hat and automatically bind it to your application using Kubernetes Operators. Creating a multi-availability-zone (multi-AZ) Kafka cluster on takes less than a minute and is completely free during our trial period. and help us shape it with your early feedback. Now, let’s see how we can meet the remaining two modernization challenges using design patterns. CHALLENGE 2: AVOIDING DUAL-WRITES Once you build a couple of microservices, you quickly realize that the hardest part about them is data. As part of their business logic, microservices often have to update their local data store. At the same time, they also need to notify other services about the changes that happened. This challenge is not so obvious in the world of monolithic applications and legacy distributed transactions. How can we avoid or resolve this situation the cloud-native way? The answer is to only modify one of the two resources—the database—and then drive the update of the second one, such as Apache Kafka, in an eventually consistent manner. Figure 10 illustrates this approach. Figure 10: The Outbox pattern. Using the with Debezium lets services execute these two tasks in a safe and consistent manner. Instead of directly sending a message to Kafka when updating the database, the service uses a single transaction to both perform the normal update and insert the message into a specific outbox table within its database. Once the transaction has been written to the database’s transaction log, Debezium can pick up the outbox message from there and send it to Apache Kafka. This approach gives us very nice properties. By synchronously writing to the database in a single transaction, the service benefits from "read your own writes" semantics, where a subsequent query to the service will return the newly persisted record. At the same time, we get reliable, asynchronous, propagation to other services via Apache Kafka. The Outbox pattern is a proven approach for avoiding dual-writes for scalable event-driven microservices. It solves the inter-service communication challenge very elegantly without requiring all participants to be available at the same time, including Kafka. I believe Outbox will become one of the foundational patterns for designing scalable event-driven microservices. CHALLENGE 3: LONG-RUNNING TRANSACTIONS While the Outbox pattern solves the simpler inter-service communication problem, it is not sufficient alone for solving the more complex long-running, distributed business transactions use case. The latter requires executing multiple operations across multiple microservices and applying consistent all-or-nothing semantics. A common example for demonstrating this requirement is the booking-a-trip use case consisting of multiple parts where the flight and accommodation must be booked together. In the legacy world, or with a monolithic architecture, you might not be aware of this problem as the coordination between the modules is done in a single process and a single transactional context. The distributed world requires a different approach, as illustrated in Figure 11.  Figure 11: The Saga pattern implemented with Debezium. The offers a solution to this problem by splitting up an overarching business transaction into a series of multiple local database transactions, which are executed by the participating services. Generally, there are two ways to implement distributed sagas: * Choreography: In this approach, one participating service sends a message to the next one after it has executed its local transaction. * Orchestration: In this approach, one central coordinating service coordinates and invokes the participating services. Communication between the participating services might be either synchronous, via HTTP or gRPC, or asynchronous, via messaging such as Apache Kafka. The cool thing here is that you can implement sagas using Debezium, Apache Kafka, and the Outbox pattern. With these tools, it is possible to take advantage of the orchestration approach and have one place to manage the flow of a saga and check the status of the overarching saga transaction. We can also combine orchestration with asynchronous communication to decouple the coordinating service from the availability of participating services and even from the availability of Kafka. That gives us the best of both worlds: orchestration and asynchronous, non-blocking, parallel communication with participating services, without temporal coupling. Combining the Outbox pattern with the Sagas pattern is an awesome, event-driven implementation option for the long-running business transactions use case in the distributed services world. See  (InfoQ) for a detailed description. Also see an of this pattern on GitHub. CONCLUSION The Strangler pattern, Outbox pattern, and Saga pattern can help you migrate from brown-field systems, but at the same time, they can help you build green-field, modern, event-driven services that are future-proof. Kubernetes, Apache Kafka, and Debezium are open source projects that have turned into de facto standards in their respective fields. You can use them to create standardized solutions with a rich ecosystem of supporting tools and best practices. The one takeaway from this article is the realization that modern software systems are like cities: They evolve over time, on top of legacy systems. Using proven patterns, standardized tools, and open ecosystems will help you create long-lasting systems that grow and change with your needs. This post was originally published on Red Hat Developers. To read the original post, check . </content><dc:creator>Unknown</dc:creator></entry><entry><title type="html">Getting started with Java 18</title><link rel="alternate" href="http://www.mastertheboss.com/java/upcoming-news-from-java-18/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/java/upcoming-news-from-java-18/</id><updated>2022-03-26T11:09:00Z</updated><content type="html">Java 18 is finally available for download! In this article we will learn some of the most interesting Enhancement Proposals (JEPs) which are now available in the JDK. Installing Java 18 Firstly, let’s download the Java 18 platform from https://jdk.java.net/18/ Choose the version for your Operating System. Then, unpack it on your machine and set ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title type="html">How to inspect a Thread Dump like a pro</title><link rel="alternate" href="http://www.mastertheboss.com/java/how-to-inspect-a-thread-dump-like-a-pro/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/java/how-to-inspect-a-thread-dump-like-a-pro/</id><updated>2022-03-25T15:41:09Z</updated><content type="html">This article will guide you in troubleshooting Java application by analysing a Thread dump with the instruments available in the JDK. We will also learn some tools to simplify our analysis. Java has mechanisms for analyzing the state of all threads of an application at a given time: Thread dumps. A thread dump is a ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title type="html">COMPLEX KIE SERVER TESTS AUTOMATION PART 3: SMART ROUTER NETWORK ISSUES</title><link rel="alternate" href="https://blog.kie.org/2022/03/smart-router.html" /><author><name>Gonzalo Muñoz Fernández</name></author><id>https://blog.kie.org/2022/03/smart-router.html</id><updated>2022-03-25T10:10:58Z</updated><content type="html">Following Murphy’s Law, whatever you do not test against will happen (M. Nygard) TL ; DR * KIE Smart Router resilience -against network issues- needs to be tested in an automated way * Testcontainers and Toxiproxy are perfect tools for easing these complex tests * Build KIE Smart Router temporary image from sources by means of Dockerfile * Parameterize tests and do not use sleep-before-check (polling is faster and more reliable) * Adopt this new motto: “whatever you do not test against, will happen” MOTIVATION: NETWORK WILL FAIL SOONER THAN LATER Modern systems are mainly distributed and connectivity is a key part of their design and operation. However, as quality-enthusiasts, we realize that it is fairly complex to test connection issues in a deterministic and automated manner, because: * involves multiple components with their interactions. * networking is built over abstractions.  * connection failures are unpredictable by nature.  In the following article, the third of a series about complex automation testing with KIE Server (see and ), we will focus on the to see how we can assure its reliability and robustness against one of the most important resilience killers: the network issues. KIE Smart Router is a component that acts as a gateway: * hides the topology of the different KIE servers to their clients, forwarding requests, and aggregating responses into a single one before coming back. * is really useful in dynamic deployment environments where the client is agnostic about KIE Servers distribution. * handles multiple connections and has implemented stability patterns (like circuit-breaker) to cope with connection error scenarios.  Let’s assume it: network issues are inevitable. Sooner or later will happen and waiting for a critical outage in production to find out how the system will perform is, without a shadow of a doubt, a recipe for pain. This is the main motivation of present work: anticipate the disaster by writing automated tests, simulating common kinds of network failures to prove the KIE Smart Router resilience. CIRCUIT BREAKER PATTERN FOR NETWORK ISSUES KIE Smart Router implements the well-known when there is a connection loss. The goal of this mechanism is to fail fast in order to prevent further consequences. Let’s see briefly how it works because later we will test it thoroughly.  The routing table is the brain of the Smart Router. Consequently, it contains the relationships among * containers (identified by an alias as well as group-artifact-version) and * server-ids (logical names in the network) with * server locations needed for redirection. There are two ways to populate this table: * By manual operation * Automatically, each KIE Server at startup will self-register into the Smart Router by passing its own id and location.   When a connection issue happens, the system immediately updates this routing table by removing the location of the failing KIE server. Open circuit! Smart router won’t forward any request to that point of failure to guard the system against cascading errors and slow responses. Apart from this, new requests are going to be balanced to another working server for that container (if provisioned). Next, the KIE Smart Router spawns a different thread of execution for periodically pinging the failing KIE Server until it reaches a maximum number of configured retries. When one of them succeeds (server connection is back again), the location is annotated again in the routing table, ready for more routine operation. Closed-circuit! NETWORK ISSUES TESTING SETUP Once we have introduced our testing scenario, let’s see the setup for putting in place the resilience test cases. Similarly to other examples brought up in this series, we will take advantage of containerized applications and library and utilities. The following figure depicts the initial configuration. Firstly, we create a network containing several KIE servers (one of them can act as a controller) connected to the KIE Smart Router with a secure/non-secure connection. Each box represents a Linux container that exposes a port to the network: * Secured KIE Servers: port 8443 * Non-secured KIE Servers: port 8080 * KIE Smart Router: port 9000 Moreover, each KIE Server deploys a different business application (kjar) in their respective KIE containers. Be aware of the different meaning of the word “container” here: the self-contained environments to run business applications. KIE containers are identified by a Group-Artifact-Version and/or alias. All of these elements comprise the System-Under-Test (SUT). In front of it, there’s our test suite acting as a client application.  DO TESTING BY PROXY Now, we want to provoke network issues into this setup in a controlled and deterministic manner from the client. The way we’ve chosen to do it is by means of “Toxiproxy” containers. is an open-source library for simulating abnormal network conditions (called toxics).  These toxics cause connection failures emulating real network issues like connection loss, poor bandwidth, timeouts, connection reset by peer, high latency and jitter, sliced data into multiple smaller packets et others. As you can see in the figure, the Toxiproxy container is a proxy that intercepts all the traffic between the KIE Smart Router and the KIE server (upstream and downstream). It exposes port 8666 to the network. It can simulate java.net exceptions like these (which fail immediately, so great for not making the tests too long): Java ExceptionToxicjava.net.SocketException: Unexpected end of file from servertimeout, limitdatajava.net.SocketException: Connection resetresetPeerjavax.net.ssl.SSLHandshakeException: Remote host terminated the handshaketimeout, limitdatajavax.net.ssl.SSLException: Connection resetresetPeer TOXIPROXIES IN THE MIDDLE OF THE WIRE We can initialize Toxiproxy in the code as shown below. Along with the out-of-the-box Shopify image, we will provide a shared network, network alias, and the log consumer to print out its logs: @Container public static ToxiproxyContainer toxiproxy = new ToxiproxyContainer(DockerImageName.parse("ghcr.io/shopify/toxiproxy:2.4.0") .asCompatibleSubstituteFor("shopify/toxiproxy")) .withNetwork(network) .withNetworkAliases(TOXIPROXY_NETWORK_ALIAS) .withLogConsumer(new Slf4jLogConsumer(logger).withPrefix("TOXIPROXY-1")); Toxyproxy will proxy the target container by invoking: proxy1 = toxiproxy.getProxy(kieServer1, KIE_HTTPS_PORT); proxy3 = toxiproxy3.getProxy(kieServer3, KIE_PORT); At this point, you might be wondering "ok, that’s the way Toxiproxy reaches the KIE server, but how should I configure the Smart Router to get to the Toxiproxy?"  Indeed, that’s a very good question. In this case, with self-registering, it’s the KIE server that sends its location (KIE_SERVER_LOCATION) to be populated into the routing table.   When creating the KIE Server, we pass this Environment variable: withEnv("KIE_SERVER_LOCATION", args.get("KIE_SERVER_LOCATION_"+nodeName)+"/kie-server/services/rest/server"); Where KIE_SERVER_LOCATION_node1/2/3 are defined as system properties (in the pom.xml or they could be overridden at launch time) org.kie.samples.server.location.node1 = https://toxiproxy:8666 org.kie.samples.server.location.node2 = https://kie-server-node2:8443 org.kie.samples.server.location.node3 = http://toxiproxy3:8666 To sum up, those KIE servers behind the Toxiproxy will pass their proxy network addresses. CONTAINERS ALL AROUND So, these are the containers in place and their origin: image contains KIE Server, Controller, and Business Central, meanwhile is a lighter image with just the KIE Server. Both are available to download from . After that, we will create temporary images from them just for testing (a.k.a. images-on-the-fly) including business applications and the rest of the needed configuration. Same for the KIE Smart Router image, but in this case, we do have to create it from scratch (no community binaries for it). Do not panic, KIE is an open-source initiative and we can generate all that we need by instructing a Dockerfile. GENERATING THE KIE SMART ROUTER IMAGE Dockerfile is like the instructions manual to build an image. It’s flexible enough to layer and skip repeated steps if nothing forces it to execute them again. Starting from a JDK base (in this case, from JBoss which already contains jboss user), it will download git and maven tools. Next, it will proceed with the cloning of the repository (its branch and URL are configurable, by default they are main and ) and the compilation of sources and their packaging. Then, it will include some properties files (for configuring the KIE Smart Router, logging, and the certificate for TLS communication) and will execute this command to import the certificate into a trust Keystore (as it is a self-signed certificate, created ad-hoc for testing purposes): keytool -importcert -noprompt -trustcacerts -alias toxiproxy-full-ks -file $ROUTER_HOME/kieks.crt -keystore /etc/pki/java/cacerts -storepass changeit An aside about certificates and TLS communication: CERTIFICATE GENERATION In order to generate, in your localhost, a self-signed certificate valid for multiple hostnames with keytool, you must include the DNS (network alias) as Subject Alternative Names (SAN) if you don’t want to get a “no name matching” exception: keytool -genkeypair -alias toxiproxy-full-ks -keyalg RSA -keysize 2048 -validity 365 -keystore serverks.pkcs12 -storetype PKCS12 -dname "cn=Kie Server,o=jbpm,c=ES" -keypass secret -storepass secret -ext san=dns:full-node1,dns:toxiproxy,dns:localhost Secondly, we will export it into a .crt file. For example, naming it as kie.crt: keytool -export -alias toxiproxy-full-ks -file kie.crt -keystore serverks.pkcs12 Enter keystore password: Certificate stored in file &lt;kie.crt&gt; KIE Smart Router image will use this one. In the KIE Server, for enabling secure connections, we must execute this jboss-cli command as part of the initialization:  security enable-ssl-http-server --key-store-path=$JBOSS_HOME/standalone/configuration/serverks.pkcs12 --key-store-password=secret FROM DOCKERFILE TO IMAGE-ON-THE-FLY Finally, the entrypoint of the container will be the standard “java -jar …” command including the $ROUTER_PROPS to enable the file configuration and its watcher. withEnv("ROUTER_PROPS", "-Djava.util.logging.config.file=$ROUTER_HOME/logging.properties -Dorg.kie.server.router.config.watcher.enabled=true -Dorg.kie.server.router.config.file=$ROUTER_HOME/smart_router.properties"); From this Dockerfile, the Testcontainers utility “ImageFromDockerfile" will build the image of the KIE Smart Router containing also the network configuration, the LogConsumer (whose purpose is avoiding sleep calls) and will wait for the expected message to consider the component "up and running": withNetwork(network); withNetworkAliases(SMARTROUTER_ALIAS); withExposedPorts(SMARTROUTER_PORT); withLogConsumer(new Slf4jLogConsumer(logger).withPrefix("SMART-ROUTER")); waitingFor(Wait.forLogMessage(".*KieServerRouter started on.*", 1).withStartupTimeout(Duration.ofMinutes(2L))); NETWORK ISSUES TEST INSIGHT                                            You can find the code and configuration for this example . Let’s give some hints on how to parameterize and structure tests for easy scale. Test cases are aimed to validate whether the component fulfills the circuit breaker pattern, making it stable and usable during hard network conditions. The routing table (kie-server-router.json file) has to be consistently updated to open and close the circuit, and a polling mechanism is launched to check when the connections are recovered. COMPLEX AS SYSTEM TESTS, STRAIGHTFORWARD AS UNIT TESTS with @MethodSource will allow us to define the different toxics to apply in each proxy for exercising the same tests in different contexts. This static method “provideToxics” returns a Stream of Arguments that will be passed to each test. We can combine the toxics as we want in our testing matrix without interfering with the implementation of the tests. Notice that we can even set up the properties of these toxics based on random values between a range (as the waiting time before a timeout): ToxicSupplier&lt;Toxic, IOException&gt; timeout3 = () -&gt; proxy3.toxics().timeout("timeout", DOWNSTREAM, getRandomTimeout(2000,5000)); When a toxic is applied (ToxicSupplier is a functional interface that defines a get method like Suppliers) for a proxy, the abnormal behavior of the network begins over that path. On the other hand, when invoking removeAllToxics method, toxics are completely wiped out. As a result, the network comes back to a healthy condition. This control flow of the impediments on the arrange-act-assert steps leverages the power of the tests. The test suite is completely self-contained, managing the resources easily, in a predictable way, like in a unit test. Here, the unit is our SUT comprising several components and connections. Finally, tests don’t rely on sleep functions to wait for the expected behavior of the SUT but actively poll over the routing table or the logs to check if the desired state is already reached before a timeout. This approach is not only faster, but furthermore, it’s also less error-prone in CI environments.  CONCLUSION: AUTOMATE NETWORK ISSUES TESTING , followed by Googlers and other major players in the industry, states that “if you liked it, then you shoulda put a test on it”. A test here means an automated test. For some critical aspects, like how the system handles network failures, these tests may have some complexity, but with new containerized tools (like Testcontainers and Toxiproxy) the effort is really worth it. Network issues won’t be completely prevented ever and modern architectures (KIE Smart Router is a good example) follow resilience and stability patterns to minimize their effects. But you will only be confident that the system exhibits the desired behavior when you write an automated test for it and this one becomes part of the CI to execute regressions.  Investing in automated testing for a great variety of network issues is, without a shadow of a doubt, a recipe for success. The post appeared first on .</content><dc:creator>Gonzalo Muñoz Fernández</dc:creator></entry><entry><title type="html">Using JavaScript and Power Fx with DMN</title><link rel="alternate" href="https://blog.kie.org/2022/03/using-javascript-and-power-fx-with-dmn.html" /><author><name>Matteo Mortari</name></author><id>https://blog.kie.org/2022/03/using-javascript-and-power-fx-with-dmn.html</id><updated>2022-03-25T08:52:01Z</updated><content type="html">In this short update, I want to share with you about an experimental feature to leverage the extensibility of the DMN specification to evaluate expressions using a plurality of expression languages, such as JavaScript, , and potentially many more! For the running example in this post, let’s use the Body Mass Index (BMI) calculation described in the : We can classify the result of the calculation, based on a standard Decision Table: The decision table has been simplified if compared to the original article from Wikipedia, but that’s irrelevant for the scope of this example. The overall DRG of the DMN model looks like this: As we expect, "Mass" and "Height" are the InputDatas of the model; then we calculate the BMI with a first Decision node. Finally, we classify the calculated BMI value, accordingly to the Decision Table above. The last step is to provide the expression for the "Calculate BMI" decision node. For example, using Power Fx idioms: It would result in this final expression for the "Calculate BMI" decision node: In this case, the resulting DMN model evaluates using two expression languages: Power Fx for the first Decision, and the default (FEEL) for the Decision Table. For another example, we could use idiomatic JavaScript: In this second case, the resulting DMN model evaluates using two expression languages: JavaScript for the first Decision, and again FEEL for the Decision Table. RUNNING THE DEMO We can now run the Kogito application. To demonstrate the BMI calculation, we naturally keep using the Swagger GUI: If you are already accustomed in using DMN models with Kogito, you will have noticed there is basically no different in the way this system behaves from an external point of view. This is what we expect! We have now defined two DMN models, using a plurality of expression languages. However, our goal is to model our decision services in the most convenient and effective way possible. In this case, for example, we have used Power Fx, or JavaScript for some calculations. The code of this demo for the curious, is available . CONCLUSIONS Don’t forget to check out the video linked above, for a live demonstration of this experimental capability! In this post, we have leveraged the extensibility of the DMN specification, in order to evaluate expressions using a plurality of expression languages. We have just used JavaScript and Power Fx with DMN! Questions? Feedback? Don’t hesitate to let us know! The post appeared first on .</content><dc:creator>Matteo Mortari</dc:creator></entry><entry><title type="html">This Week in JBoss - 25 March 2022</title><link rel="alternate" href="https://www.jboss.org/posts/weekly-2022-03-25.html" /><category term="quarkus" /><category term="kubernetes" /><category term="java" /><category term="infinispan" /><category term="jakarta ee" /><category term="wildfly" /><category term="ansible" /><category term="azure app service" /><author><name>Francesco Marchioni</name><uri>https://www.jboss.org/people/francesco-marchioni</uri><email>do-not-reply@jboss.com</email></author><id>https://www.jboss.org/posts/weekly-2022-03-25.html</id><updated>2022-03-25T00:00:00Z</updated><content type="html">&lt;article class="" data-tags="quarkus, kubernetes, java, infinispan, jakarta ee, wildfly, ansible, azure app service"&gt; &lt;h1&gt;This Week in JBoss - 25 March 2022&lt;/h1&gt; &lt;p class="preamble"&gt;&lt;/p&gt;&lt;p&gt;Happy Friday, everyone!&lt;/p&gt; &lt;p&gt;Here is another edition of the JBoss Editorial with exciting news and updates from your JBoss communities.&lt;/p&gt;&lt;p&gt;&lt;/p&gt; &lt;div class="sect1"&gt; &lt;h2 id="_release_roundup"&gt;Release roundup&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Here are the most recent releases for this edition:&lt;/p&gt; &lt;div class="ulist square"&gt; &lt;ul class="square"&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://quarkus.io/blog/quarkus-2-7-5-final-released/"&gt;Quarkus 2.7.5&lt;/a&gt; - There is a new maintenance release with a new round of bugfixes and documentation improvements. This should be a safe upgrade upgrade for anyone already using 2.7. More details on the &lt;a href="https://github.com/quarkusio/quarkus/wiki/Migration-Guide-2.7"&gt;Migration Guide 2.7&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/kiegroup/kogito-images/releases/tag/1.19.0"&gt;Kogito 1.19.0&lt;/a&gt; - We are glad to announce that the Kogito 1.19.0 release is now available!.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://infinispan.org/download/"&gt;Infinispan 14.0.0.Dev01&lt;/a&gt; - Infinispan 14 GA is almost ready! Expect some cool features such as Redis (RESP) endpoints, new MP Metrics with Micrometer, clustering and endpoint metrics in Prometheus, FIPS compatible Infinispan Installation, Cross-site replication memory and batching improvements and Dynamic Role-Based Access Control&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_write_kubernetes_in_java_with_the_java_operator_sdk_part_2"&gt;Write Kubernetes in Java with the Java Operator SDK (Part 2)&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/22/write-kubernetes-java-java-operator-sdk-part-2"&gt;Write Kubernetes in Java with the Java Operator SDK, Part 2&lt;/a&gt;, by Christophe Laprun&lt;/p&gt; &lt;p&gt;In this post, Christophe teach us how to use the Java Operator SDK and its Quarkus extension to build a sample application as you take a deeper dive into writing Kubernetes Operators in Java.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_deploy_infinispan_automatically_with_ansible"&gt;Deploy Infinispan automatically with Ansible&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/21/deploy-infinispan-automatically-ansible"&gt;Deploy Infinispan automatically with Ansible&lt;/a&gt;, by Romain Pelisse&lt;/p&gt; &lt;p&gt;In this article from Romain, you will learn how to use Ansible to cover all repetitive work to provision Infinispan. It covers everything from downloading software, preparing the environment (user, group, firewall), deploying the binary files and the configuration, setting up the service in systemd, etc. That’s a great way to get started with Infinispan and Ansible.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_clustering_support_for_jboss_eap_on_azure_app_service_tech_preview"&gt;Clustering support for JBoss EAP on Azure App Service (Tech Preview)&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/15/preview-clustering-support-jboss-eap-azure-app-service"&gt;Clustering support for JBoss EAP on Azure App Service (Tech Preview)&lt;/a&gt;, by James Falkner and Jason Freeberg&lt;/p&gt; &lt;p&gt;If you want to try out a preview of JBoss EAP clustering on Azure App Service then this article is for you! The combination of JBoss EAP, a leading Jakarta EE platform, with Microsoft Azure, a leading cloud platform, gives JBoss EAP users a powerful path to the cloud.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_quarkus_newsletter_18_march"&gt;Quarkus Newsletter #18 - March&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="https://quarkus.io/blog/quarkus-newsletter-18/"&gt;Quarkus March newsletter&lt;/a&gt;, By James Cobb&lt;/p&gt; &lt;p&gt;This newsletter covers what’s new with Java 17 and containers, discusses LogicDrop and Vaadin’s path to using Quarkus, and get a look at Continuous testing with Quarkus.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_quarkus_migration_tips"&gt;Quarkus Migration Tips&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="http://www.mastertheboss.com/soa-cloud/quarkus/quarkus-migration-tips/"&gt;Quarkus Migration Tips&lt;/a&gt;, by Francesco Marchioni&lt;/p&gt; &lt;p&gt;In this article from mastertheboss.com you will learn which are the available guidelines to migrate Quarkus applications and tools that can help you to simplify your update strategy&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_youtube_video_build_deploy_wildfly_quickstarts_on_openshift"&gt;Youtube video: Build &amp;#38; Deploy WildFly Quickstarts on OpenShift&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=Y2En5miRKjY"&gt;Build &amp;#38; Deploy WildFly Quickstarts on OpenShift&lt;/a&gt;, by Jeff Meslin&lt;/p&gt; &lt;p&gt;Finally, from WildFly’s youtube channel check this video by Jeff Meslin to learn how to build and deploy a quickstart for WildFly on OpenShift&lt;/p&gt; &lt;p&gt;Jeff shows how to deploy the microprofile-config quickstart for WildFly on the Developer Sandbox for Red Hat OpenShift. This uses the Helm Chart for WildFly to configuring building and deploying WildFly applications.&lt;/p&gt; &lt;p&gt;&lt;em&gt;That’s all folks! Please join us again in two weeks for another round of our JBoss editorial!&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="author"&gt; &lt;pfe-avatar pfe-shape="circle" pfe-pattern="squares" pfe-src="/img/people/francesco-marchioni.png"&gt;&lt;/pfe-avatar&gt; &lt;span&gt;Francesco Marchioni&lt;/span&gt; &lt;/div&gt;&lt;/article&gt;</content><dc:creator>Francesco Marchioni</dc:creator></entry><entry><title>Red Hat Developer roundup: Best of March 2022</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/03/24/red-hat-developer-roundup-best-march-2022" /><author><name>Red Hat Developer Editorial Team</name></author><id>6a2bad30-cb7f-432d-9c3a-88c8e666c6b7</id><updated>2022-03-24T07:00:00Z</updated><published>2022-03-24T07:00:00Z</published><summary type="html">&lt;p&gt;Welcome to our monthly recap of the articles we published in March 2022! This month, Red Hat Developer readers flocked to articles to help them write code on the platforms they trust. You can learn more about &lt;a href="https://developers.redhat.com/articles/2022/03/10/modular-perl-red-hat-enterprise-linux-8"&gt;modular Perl in Red Hat Enterprise 8&lt;/a&gt;, get into the details of &lt;a href="https://developers.redhat.com/articles/2022/03/02/introduction-nodejs-reference-architecture-part-7-code-coverage"&gt;testing and code coverage in the Node.js reference architecture&lt;/a&gt;, or dive deeper into Quarkus in the &lt;a href="https://developers.redhat.com/articles/2022/03/03/rest-api-error-modeling-quarkus-20"&gt;latest installment of our Quarkus from the ground up series&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;And there's much more as well! Read on for the March highlights.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: See the end of this article for the full lineup published in March 2022.&lt;/p&gt; &lt;h2&gt;Podman and container development&lt;/h2&gt; &lt;p&gt;Are you a &lt;a href="https://developers.redhat.com/topics/dotnet"&gt;.NET&lt;/a&gt; user interested in rolling out &lt;a href="https://developers.redhat.com/topics/containers"&gt;containerized&lt;/a&gt; applications with Podman? Another one of our most popular articles of the month explains how to &lt;a href="https://developers.redhat.com/articles/2022/03/21/hello-podman-using-net"&gt;control Podman from .NET&lt;/a&gt;. .NET users can also get tips on how to &lt;a href="https://developers.redhat.com/articles/2022/02/22/debug-net-applications-running-local-containers-vs-code"&gt;debug .NET applications running in local containers with VS Code&lt;/a&gt;; and if you're working with Red Hat CodeReady Workspaces, you can find out more about &lt;a href="https://developers.redhat.com/articles/2022/02/28/simplify-container-development-red-hat-codeready-workspaces"&gt;simplifying container development with that service&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;OpenShift: What's new and what's fast&lt;/h2&gt; &lt;p&gt;Version 4.10 of the &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift Container Platform&lt;/a&gt; is here, and that's big news for the many developers who are deploying their container-based workloads on that platform. If you need a deep dive into &lt;a href="https://developers.redhat.com/articles/2022/03/22/whats-new-developers-openshift-410-console"&gt;what's for developers in the OpenShift 4.10 console&lt;/a&gt;, Red Hat Developer has you covered.&lt;/p&gt; &lt;p&gt;Want to learn more about how to get started with Red Hat OpenShift quickly? Check out our articles on &lt;a href="https://developers.redhat.com/articles/2022/03/01/package-and-run-your-java-maven-application-openshift-seconds"&gt;packaging and running a Java Maven application on OpenShift in seconds&lt;/a&gt; and &lt;a href="https://developers.redhat.com/articles/2022/03/04/create-azure-red-hat-openshift-cluster-less-5-minutes"&gt;creating an Azure Red Hat OpenShift cluster in less than five minutes&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Do more with Kafka&lt;/h2&gt; &lt;p&gt;Developers love &lt;a href="https://developers.redhat.com/topics/kafka-kubernetes"&gt;Kafka&lt;/a&gt; for its ability to move truly massive amounts of data. Clustering is one of the keys to Kafka's power, but how many Kafka clusters does your infrastructure require? Red Hat Developer's most popular article in March tries to answer the question of whether you need a &lt;a href="https://developers.redhat.com/articles/2022/03/10/which-better-single-kafka-cluster-rule-them-all-or-many"&gt;single Kafka cluster—or many clusters—to rule them all&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Meanwhile, for those interested in &lt;a href="https://developers.redhat.com/topics/event-driven"&gt;event-driven&lt;/a&gt; and &lt;a href="https://developers.redhat.com/topics/serverless-architecture"&gt;serverless&lt;/a&gt; architectures, we've offered a guide to &lt;a href="https://developers.redhat.com/articles/2022/03/14/process-apache-kafka-records-knatives-serverless-architecture"&gt;processing Apache Kafka records with Knative's serverless architecture&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Understand Java's nitty-gritty details&lt;/h2&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt; developers looking to learn more about how their code works under the hood got some treats this month. We did a deep dive into &lt;a href="https://developers.redhat.com/articles/2022/03/16/range-check-elimination-loops-openjdks-hotspot-jvm"&gt;range checks&lt;/a&gt;, a technique the HotSpot JVM uses to improve performance. For those looking to use Cryostat to instrument and monitor their own code, we offered advice on &lt;a href="https://developers.redhat.com/articles/2022/03/08/inject-custom-jdk-flight-recorder-events-containerized-applications"&gt;injecting custom JDK Flight Recorder events in containerized applications&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Choose the best Camel for your integration ride&lt;/h2&gt; &lt;p&gt;Apache Camel is the most popular open source integration framework today, and has evolved to support new environments such as containers on Kubernetes while continuously improving the developer experience. Want to find out more about all the ways you can use Camel and why each came into being? Read the &lt;a href="https://developers.redhat.com/articles/2022/03/14/choose-best-camel-your-integration-ride-part-1"&gt;first&lt;/a&gt;, &lt;a href="https://developers.redhat.com/articles/2022/03/15/choose-best-camel-your-integration-ride-part-2"&gt;second&lt;/a&gt;, and &lt;a href="https://developers.redhat.com/articles/2022/03/16/choose-best-camel-your-integration-ride-part-3"&gt;third&lt;/a&gt; parts of our series on the topic.&lt;/p&gt; &lt;h2&gt;March 2022 on Red Hat Developer&lt;/h2&gt; &lt;p&gt;Here's the full lineup of articles published on Red Hat Developer so far this month:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/10/which-better-single-kafka-cluster-rule-them-all-or-many"&gt;Which is better: A single Kafka cluster to rule them all, or many?&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/10/modular-perl-red-hat-enterprise-linux-8"&gt;Modular Perl in Red Hat Enterprise Linux 8&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/02/introduction-nodejs-reference-architecture-part-7-code-coverage"&gt;Introduction to the Node.js reference architecture, Part 7: Code coverage&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/01/package-and-run-your-java-maven-application-openshift-seconds"&gt;Package and run your Java Maven application on OpenShift in seconds&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/03/rest-api-error-modeling-quarkus-20"&gt;REST API error modeling with Quarkus 2.0&lt;/a&gt;&lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/23/quarkus-superheroes-managed-services-save-day"&gt;Quarkus Superheroes: Managed services save the day&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/23/use-valgrind-memcheck-custom-memory-manager"&gt;Use Valgrind Memcheck with a custom memory manager&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/23/learn-how-build-train-and-run-pytorch-model"&gt;Learn how to build, train, and run a PyTorch model&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/22/whats-new-developers-openshift-410-console"&gt;What’s new for developers in the OpenShift 4.10 console&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/22/write-kubernetes-java-java-operator-sdk-part-2"&gt;Write Kubernetes in Java with the Java Operator SDK, Part 2&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/21/deploy-infinispan-automatically-ansible"&gt;Deploy Infinispan automatically with Ansible&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/11/easier-way-generate-pdfs-html-templates"&gt;An easier way to generate PDFs from HTML templates&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/04/create-azure-red-hat-openshift-cluster-less-5-minutes"&gt;Create an Azure Red Hat OpenShift cluster in less than 5 minutes&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/21/hello-podman-using-net"&gt;Hello Podman using .NET&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/14/choose-best-camel-your-integration-ride-part-1"&gt;Choose the best Camel for your integration ride, Part 1&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/14/process-apache-kafka-records-knatives-serverless-architecture"&gt;Process Apache Kafka records with Knative's serverless architecture&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/10/kafka-monthly-digest-february-2022"&gt;Kafka Monthly Digest: February 2022&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/07/manage-python-security-thoths-cloud-based-dependency-resolver"&gt;Manage Python security with Thoth's cloud-based dependency resolver&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/15/choose-best-camel-your-integration-ride-part-2"&gt;Choose the best camel for your integration ride, Part 2&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/16/range-check-elimination-loops-openjdks-hotspot-jvm"&gt;Range check elimination in loops in OpenJDK's HotSpot JVM&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/09/test-github-projects-github-actions-and-testing-farm"&gt;Test GitHub projects with GitHub Actions and Testing Farm&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/18/nodejs-community-update"&gt;Node.js community update&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/16/choose-best-camel-your-integration-ride-part-3"&gt;Choose the best camel for your integration ride, Part 3&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/15/preview-clustering-support-jboss-eap-azure-app-service"&gt;Preview: Clustering support for JBoss EAP on Azure App Service&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/08/inject-custom-jdk-flight-recorder-events-containerized-applications"&gt;Inject custom JDK Flight Recorder events in containerized applications&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/04/data-conversion-pandas-dataframes-3-approaches-try"&gt;Data conversion in Pandas dataframes: 3 approaches to try&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/02/22/debug-net-applications-running-local-containers-vs-code"&gt;Debug .NET applications running in local containers with VS Code&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/02/28/simplify-container-development-red-hat-codeready-workspaces"&gt;Simplify container development with Red Hat CodeReady Workspaces&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/02/24/inspecting-containerized-python-applications-cluster"&gt;Inspecting containerized Python applications in a cluster&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/02/25/enforce-code-consistency-clang-format"&gt;Enforce code consistency with clang-format&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/02/24/sql-cache-stores-and-more-data-grid-83"&gt;SQL cache stores and more in Data Grid 8.3&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/03/24/red-hat-developer-roundup-best-march-2022" title="Red Hat Developer roundup: Best of March 2022"&gt;Red Hat Developer roundup: Best of March 2022&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Red Hat Developer Editorial Team</dc:creator><dc:date>2022-03-24T07:00:00Z</dc:date></entry><entry><title type="html">Portfolio Architecture Examples - Healthcare Collection</title><link rel="alternate" href="http://www.schabell.org/2022/03/portfolio-architecture-examples-telco-collection.html" /><author><name>Eric D. Schabell</name></author><id>http://www.schabell.org/2022/03/portfolio-architecture-examples-telco-collection.html</id><updated>2022-03-24T06:00:00Z</updated><content type="html">Figure 1: The portfolio architecture process For a few years now we've been working on a project we have named . These are based on selecting a specific use case we are seeing used in the real world by customers and then finding implementations of that case using three or more products from the Red Hat portfolio. This basic premise is used as the foundation, but many aspects of open source are included in both the process and the final product we have defined. There is a community, where we share the initial project kickoff with a group of architects and use their initial feedback from the start. We also present the architecture product we've created right at the end before we publish to ensure usability by architects in the field. The final publish product includes some internal only content around the customer projects researched, but most of the content is through various open source channels.  This article is sharing an overview of the product we've developed, what's available to you , and concludes by sharing a collection of architectures we've published. INTRODUCTION The basic premise of a portfolio architecture is that it's a use case with two to three actual implementations that can be researched and includes the use of a minimum of three products. This is the ideal foundation for a project to start, but we encountered a problem with use cases containing emerging technologies or emerging domains in the market. To account for these we've chosen to note the fact that these are opinionated architectures based on internal reference architectures.  The product has been defined as complete for publishing when it contains the following content: * Short use case definition * Diagrams - logical, schematic (physical), and detail diagrams * Public slide deck containing the use case story and architecture diagrams * Internal slide deck containing both the pubic deck content and the confidential customer research * Video (short) explanation of the architecture * Either a technical brief document or one or more articles covering the solution architecture Note that the above items noted in italics are all freely available to you online in the Red Hat Portfolio Architecture Center or in the Portfolio Architecture Examples repository. FIGURE 2: LOGICAL DIAGRAM DESIGN TEMPLATE TOOLING AND WORKSHOPS The progress towards our products required a good idea of how we wanted to diagram our architectures. We chose to keep them very generic and simple in style to facilitate all levels of conversation around a particular use case without getting bogged down in notational discussions.  A simple three level design for our architectures was captured by using logical, schematic, and detail diagrams. All of these have been integrated in with pre-defined templates and icons for easily getting started. Furthermore, we've developed a tooling workshop to quickly ramp up on the design methods and tooling we've made available. It's called , has been featured in several. HEALTHCARE COLLECTION The collection featured today is centred around architectures in the healthcare domain. There are two architectures in this collection and we'll provide a short overview of each, leaving the in depth exploration as an exercise for the reader. Figure 3: Healthcare architecture collection In each of these architecture overviews you'll find a table of contents outlining the technologies used, several example schematic diagrams with descriptions, and a link in the last section to open the diagrams directly into the online tooling in your browser. Intelligent DaaS (Data as a Service) is about building and delivery of systems and platforms in a secure and scalable manner while driving data needs for moving towards consumerisation in healthcare. Feel free to explore this portfolio architecture by clicking on the diagram below. Edge Medical Diagnosis is accelerating medical diagnosis using condition detection in medical imagery with AI/ML at medical facilities. Feel free to explore this portfolio architecture by clicking on the diagram below. If you are interested in more architecture solutions like these, feel free to export the and stay tuned for more collection overviews.</content><dc:creator>Eric D. Schabell</dc:creator></entry></feed>
